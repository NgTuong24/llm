{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "uZR3iGJJtdDE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uZR3iGJJtdDE",
        "outputId": "a19d9eaa-842d-4fdc-a91f-e9665ff227ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.10 (from langchain)\n",
            "  Downloading langchain_core-0.2.11-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.10->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-core-0.2.11 langchain-text-splitters-0.2.2 langsmith-0.1.83 orjson-3.10.6\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.6 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.6)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.11)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (2.8.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (2.20.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.6 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-6.1.9-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting pyreqwest-impersonate>=0.4.9 (from duckduckgo-search)\n",
            "  Downloading pyreqwest_impersonate-0.4.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyreqwest-impersonate, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-6.1.9 pyreqwest-impersonate-0.4.9\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-1.0.7-py3-none-any.whl (36 kB)\n",
            "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain_google_genai)\n",
            "  Downloading google_generativeai-0.7.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.2.11)\n",
            "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (0.1.83)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (8.4.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.20.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.63.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2024.6.2)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai, langchain_google_genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.4\n",
            "    Uninstalling google-ai-generativelanguage-0.6.4:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.4\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.5.4\n",
            "    Uninstalling google-generativeai-0.5.4:\n",
            "      Successfully uninstalled google-generativeai-0.5.4\n",
            "Successfully installed google-ai-generativelanguage-0.6.6 google-generativeai-0.7.1 langchain_google_genai-1.0.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "2e19ba4d55ee465d9b0dadcd602535d6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install -U duckduckgo-search\n",
        "!pip install langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyAk2SGsbPm5H-6K-rNgnIhQsBYwkm2GHhE'\n",
        "genai.configure(api_key='AIzaSyAk2SGsbPm5H-6K-rNgnIhQsBYwkm2GHhE')"
      ],
      "metadata": {
        "id": "l4hmTM1-wV5N"
      },
      "id": "l4hmTM1-wV5N",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import (\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from operator import itemgetter\n",
        "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "from langchain_google_genai import GoogleGenerativeAI"
      ],
      "metadata": {
        "id": "sDMHhuIYwV7a"
      },
      "id": "sDMHhuIYwV7a",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OutputNameEntity(BaseModel):\n",
        "    名前: str = Field(description=\"エンティティの名前またはヘッダーはコンテキスト内で抽出されます\")\n",
        "\n",
        "class OutputQuestion(BaseModel):\n",
        "    質問: str = Field(description=\"質問は財務上の説明、社会的背景について尋ねます\")"
      ],
      "metadata": {
        "id": "ROUKIUAHwV-K"
      },
      "id": "ROUKIUAHwV-K",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_output_name_entity(result_entity, limited_entity=10):\n",
        "        \"\"\"\n",
        "        result_entity: model trả về\n",
        "        limited_entity: giới hạn số thực thể\n",
        "        Returns: list_entity [\"\", \"\", ..]\n",
        "        -------\n",
        "        \"\"\"\n",
        "        list_entity = []\n",
        "        json_object = \"\"\n",
        "        if ('{' and '}') in result_entity:\n",
        "            json_object = json.loads(result_entity[result_entity.find('{'):result_entity.find('}') + 1])\n",
        "        # print(json_object)\n",
        "        if len(json_object):\n",
        "            key = list(json_object.keys())[0]\n",
        "            for ind, obj in enumerate(json_object[key]):\n",
        "                list_entity.append(obj)\n",
        "                if ind > limited_entity:  # SL name entity\n",
        "                    break\n",
        "        # list_to_str = \"\\n\\n\".join(list_entity)\n",
        "        return list_entity\n",
        "def format_output_of_docs_search(docs: str):\n",
        "        \"\"\"\n",
        "        docs <str>: result of Search api\n",
        "        Returns: get \"snippet\" -> input of model\n",
        "        -------\n",
        "        \"\"\"\n",
        "        key = ['snippet:', 'title:', 'link:']\n",
        "        docs = docs[1:-1]\n",
        "        list_ = docs.split(\"],\")\n",
        "        document_snippet = \"\"\n",
        "        document_title = \"\"\n",
        "        for doc in list_:\n",
        "            ind_0 = doc.find(key[0])\n",
        "            ind_1 = doc.find(key[1])\n",
        "            ind_2 = doc.find(key[2])\n",
        "            document_snippet += doc[ind_0: ind_1]\n",
        "            document_title += doc[ind_1: ind_2]\n",
        "        return document_snippet, document_title\n",
        "\n",
        "def format_docs_to_links(docs: str):\n",
        "        \"\"\"\n",
        "        docs <str>: result of Search api\n",
        "        Returns: (citation) source: title\n",
        "                                    link\n",
        "        -------\n",
        "        \"\"\"\n",
        "        key = ['snippet:', 'title:', 'link:']\n",
        "        docs = docs[1:-1]\n",
        "        list_ = docs.split(\"],\")\n",
        "        print(\"--------------\")\n",
        "        print(list_)\n",
        "        print(\"--------------\")\n",
        "\n",
        "        # list_ = [list_[0]]\n",
        "        links = []\n",
        "        for doc in list_:\n",
        "            ind_2 = doc.find(key[1])  # title\n",
        "            ind_3 = doc.find(key[2])  # link source\n",
        "            links.append(doc[ind_2 + 7:ind_3])\n",
        "            links.append(doc[ind_3 + 6:])\n",
        "        return links\n",
        "def check_data_output(entity, result_search):\n",
        "#   {'answer': '矢野経済研究所は、日本の市場調査会社です。人材ビジネス、ギフト市場、オタク市場など、さまざまな分野の市場調査を実施しています。\\n\\n - **人材ビジネス市場**に関する調査では、コロナ禍からの経済活動の回復や不安定な海外情勢による先行き不透明感などを背景に、再就職支援業市場の成長が見込まれています。\\n - **ギフト市場**に関する調査では、2023年の市場規模や動向が分析されています。\\n - **オタク市場**に関する調査では、音声合成ソフト、アニメ、同人誌など、主要14分野の市場規模や成長分野、参入企業動向、将来展望が分析されています。コロナ禍の影響やデジタル販売の動向についても解説されています。\\n\\n矢野経済研究所は、これらの市場調査結果を企業のマーケティング戦略や新規事業開発などに役立つ情報として提供しています。 \\n',\n",
        "#  'context': ['人材ビジネス市場に関する調査を実施（2023年） | ニュース・トピックス | 市場調査とマーケティングの矢野経済研究所, ',\n",
        "#   'https://www.yano.co.jp/press-release/show/press_id/3371']}\n",
        "        if entity in result_search['answer'] or entity in result_search['context'][0]:\n",
        "            return True\n",
        "        else:\n",
        "            return False"
      ],
      "metadata": {
        "id": "kPfzGqrTwWAq"
      },
      "id": "kPfzGqrTwWAq",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_llm = GoogleGenerativeAI(model=\"models/gemini-1.5-pro-001\", temperature=0.1)\n",
        "wrapper = DuckDuckGoSearchAPIWrapper(region=\"jp-jp\", time=\"y\", max_results=1) # us-en  # jp-jp\n",
        "search = DuckDuckGoSearchResults(api_wrapper=wrapper, source=\"news\", max_results=10)"
      ],
      "metadata": {
        "id": "V3LwBEwiwWDC"
      },
      "id": "V3LwBEwiwWDC",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_analytic = \"\"\"\n",
        "  回答は日本語でなければなりません。\n",
        "  1. この文脈に基づいて{context}\n",
        "  GDP、購買力、業界平均成長、市場トレンド、SWOT分析、市場の成長ドライバー、3C分析のどのデータで分析したのかを提示してください。考慮する市場は日本です。\n",
        "  以前に提供した情報と重複する情報は絶対に出さないでください。\n",
        "  可能であれば、分析に使用した白書などのデータの出典と発表時期を提供してください。特定の情報源を特定できない場合は、AIによって収集された情報であることを明記してください。\n",
        "  2. この文脈に基づいて{context}\n",
        "  収益を予測するためにどのような方法を使用していますか？上記の予測を簡単に提示できるように教えてください。\n",
        "  以前に提供した情報と重複する情報は絶対に出さないでください。\n",
        "  回答は日本語でなければなりません。\n",
        "\"\"\"\n",
        "\n",
        "template_get_name_entity = \"\"\"\n",
        "    あなたは 生成AI アシスタントモデルで、キーワードを抽出しています。\n",
        "    {context}はコンテキストです。\n",
        "    {context}からキーワードを、上記の予測の根拠を説明するために使用したデータ (存在する場合) を含む内容を含む出典のフレーズで絶対に抽出してください。\n",
        "    結果は以下のJSON型式で出してください。返される結果は、キーが 1 つだけの JSON 構造です。\n",
        "    \"keywords\": [出典：〇〇（〇年版）, 出典：〇〇（〇年版）];\n",
        "    注記：\n",
        "    1. 見出しを最も一般的なレベルに並べ替え、数を 10 未満に制限します。\n",
        "    2. 日本語で回答する必要があります。\n",
        "\"\"\"\n",
        "\n",
        "template_get_question = \"\"\"\n",
        "抽出されたキーワードは {list_name_entity} とそれらのキーワードを含むコンテンツは {context} に基づきます。\n",
        "各事業体に関連する質問を作成し、説明を裏付けるために業界の動向、政治的および経済的要因、その他の要因に関するデータを収集しました。結果は、政府、監査会社、調査会社などの最も信頼できる情報源からの市場、業界、経済、政治レポートでなければなりません。\n",
        "意味の説明などを尋ねる質問はしないでください。（例えば「〇〇とは？」など）\n",
        "質問生成 AI モデルの目標は、外部データと財務数値を検索し、返された結果の {context} を説明および正当化することです。このような意味のある質問の作成では、予測の根拠を説明するために使用したデータ (存在する場合) を含む内容を含むフレーズである必要があります。それらを抽出してください。\n",
        "結果は以下のJSON型式で出してください。返される結果は、キーが 1 つだけの JSON 構造です。\n",
        "\"question\": [question1, question2, ...]\n",
        "注記：\n",
        "1. 日本語で回答してください。\n",
        "2. 質問を繰り返さないでください。\n",
        "3. 質問に答える記事がない場合、または回答がない場合は、結果は表示されません。\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "template_search_api = \"\"\"\n",
        "文脈に基づいて\n",
        "質問 の回答を検索した後に DuckDuckGoSearch で見つかったスニペット, {snippets}\n",
        "関連する財務および社会分析。より詳細な説明を提供し、各年の財務数値を示して説明し を正当化してください。\n",
        "注:\n",
        "1. 回答は日本語でなければなりません。\n",
        "2. 質問を繰り返したり、要求された以上の情報を尋ねたりしないでください。\n",
        "3. 質問に答える記事がない場合、または回答がない場合、結果は表示されません。\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sO-3AlcXwWFz"
      },
      "id": "sO-3AlcXwWFz",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt_pl = PromptTemplate.from_template(template_pl)\n",
        "prompt_analytic = PromptTemplate.from_template(template_analytic)\n",
        "\n",
        "parser_name = JsonOutputParser(pydantic_object=OutputNameEntity)\n",
        "\n",
        "prompt_get_name_entity = PromptTemplate(\n",
        "    template=template_get_name_entity,\n",
        "    input_variables=[\"context\"],\n",
        "    partial_variables={\"format_instructions\": parser_name.get_format_instructions()},\n",
        ")\n",
        "\n",
        "parser_question = JsonOutputParser(pydantic_object=OutputNameEntity)\n",
        "\n",
        "prompt_get_question= PromptTemplate(\n",
        "    template=template_get_question,\n",
        "    input_variables=[\"snippets\"],\n",
        "    partial_variables={\"format_instructions\": parser_question.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompt_search_api = PromptTemplate.from_template(template_search_api)"
      ],
      "metadata": {
        "id": "Vj5jGa7NwWIK"
      },
      "id": "Vj5jGa7NwWIK",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_analytic = (\n",
        "    prompt_analytic\n",
        "    | model_llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "chain_get_name_entity = (\n",
        "    prompt_get_name_entity\n",
        "    | model_llm\n",
        "    | StrOutputParser()\n",
        "    | format_output_name_entity\n",
        ")\n",
        "chain_get_question = (\n",
        "    prompt_get_question\n",
        "    | model_llm\n",
        "    | StrOutputParser()\n",
        "    | format_output_name_entity\n",
        ")\n",
        "\n",
        "answer = prompt_search_api | model_llm | StrOutputParser()\n",
        "\n",
        "format_out_docs = itemgetter(\"docs\") | RunnableLambda(format_output_of_docs_search)\n",
        "format_out = itemgetter(\"docs\") | RunnableLambda(format_docs_to_links)\n",
        "chain_search = (\n",
        "    RunnableParallel(question=RunnablePassthrough(), docs=search)\n",
        "    .assign(snippets=format_out_docs)  # output key vao assign\n",
        "    .assign(answer=answer)\n",
        "    .assign(context=format_out)\n",
        ")\n"
      ],
      "metadata": {
        "id": "pgQq0N5_wWLC"
      },
      "id": "pgQq0N5_wWLC",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_pl = \"\"\"\n",
        "経営分析・事業計画 [ 収益予測 ]\n",
        "2022年3月期実績 2023年3月期実績 2024年3月期予測 2025年3月期予測 2026年3月期予測 2027年3月期予測 2028年3月期予測\n",
        "損益計算書\n",
        "売上高  462,804 766,200 842,820 927,133 1,020,159   1,123,387   1,238,288\n",
        "売上原価    3,086   6,086   6,590   7,133   7,719   8,352   9,036\n",
        "売上総利益  459,718 760,113 836,230 919,999 1,012,440   1,115,034   1,229,252\n",
        "販売費及び一般管理費    264,677 343,196 389,575 441,661 499,828 564,602 636,562\n",
        "営業利益    195,040 416,917 446,655 478,338 512,612 550,432 592,690\n",
        "営業外収益  26  26  28  30  32  34  36\n",
        "営業外費用  583 583 631 683 739 800 865\n",
        "経常利益    194,484 416,361 446,052 478,085 512,205 549,976 592,281\n",
        "特別利益    0   0   0   0   0   0   0\n",
        "特別損失    3,636   0   0   0   0   0   0\n",
        "税金等調整前当期純利益  190,847 416,361 446,052 478,085 512,205 549,976 592,281\n",
        "法人税等合計    57,254  124,908 133,816 143,426 153,662 164,593 176,284\n",
        "当期純利益  133,593 291,453 312,236 334,659 358,543 385,383 416,007\n",
        "貸借対照表\n",
        "資産合計    695,027 992,895 1,126,492   1,277,880   1,448,813   1,641,260   1,857,414\n",
        "流動資産    651,579 930,827 1,064,424   1,215,708   1,386,546   1,578,897   1,794,751\n",
        "現金及び預金    113,707 162,439 296,055 443,710 612,699 806,868 1,029,286\n",
        "売上債権    80,126  114,465 126,912 140,593 155,632 172,165 190,382\n",
        "その他流動資産  457,746 653,923 641,457 631,405 618,215 600,864 594,083\n",
        "固定資産    43,448  62,068  62,068  62,068  62,068  62,068  62,068\n",
        "投資その他の資産    43,448  62,068  62,068  62,068  62,068  62,068  62,068\n",
        "繰延資産    0   0   0   0   0   0   0\n",
        "負債合計    21,571  30,816  33,898  37,288  41,017  45,119  49,630\n",
        "流動負債    61,823  88,321  97,153  106,870 117,557 129,313 142,244\n",
        "その他流動負債  61,823  88,321  97,153  106,870 117,557 129,313 142,244\n",
        "固定負債    21,509  30,728  33,801  37,188  40,907  44,997  49,483\n",
        "長期借入金  21,509  30,728  33,801  37,188  40,907  44,997  49,483\n",
        "純資産合計  673,456 962,079 1,092,594   1,240,592   1,407,796   1,596,141   1,807,784\n",
        "株主資本    118,647 169,496 381,732 616,401 885,955 1,192,838   1,540,345\n",
        "資本金  70,000  100,000 100,000 100,000 100,000 100,000 100,000\n",
        "利益剰余金  48,647  69,496  281,732 516,401 785,955 1,092,838   1,440,345\n",
        "その他包括利益累計額    1   0   0   0   0   0   0\n",
        "新株予約権  1   0   0   0   0   0   0\n",
        "予測の根拠\n",
        "\n",
        "売上高:\n",
        "\n",
        "2024年3月期: サステナビリティ・ESG経営への関心の高まりを背景に、顧客企業数は前年比15%増の成長を見込む。それに伴い、売上高も15%増加すると予測。\n",
        "2025年3月期: 顧客企業数の増加は13%と予測。加えて、既存顧客へのクロスセル、アップセル施策が奏功し、顧客一人当たりの売上も増加するため、売上高は10%増加すると予測。\n",
        "2026年3月期: 顧客企業数の増加は8%と予測。既存顧客へのサービス浸透により、売上高は9%増加すると予測。\n",
        "2027年3月期: 顧客企業数の増加は7%と予測。サービスの安定的な利用と、新規サービスの導入により、売上高は8%増加すると予測。\n",
        "2028年3月期: 顧客企業数の増加は7%と予測。市場の成熟に伴い、売上高の成長は鈍化傾向となるが、7%の増加を見込む。\n",
        "売上原価:\n",
        "\n",
        "売上高の増加に伴い、比例的に増加すると予測。\n",
        "販売費及び一般管理費:\n",
        "\n",
        "2024年3月期: 営業体制強化のための人材採用、広告宣伝費の増加により、売上高に対して増加傾向となる。売上高比で6ポイント増加すると予測。\n",
        "2025年3月期: 引き続き、人材採用、広告宣伝費への投資は継続するものの、売上高の増加に伴い、売上高比は2ポイント増加に抑えられると予測。\n",
        "2026年3月期: 売上高の増加に伴い、売上高比は横ばいとなると予測。\n",
        "2027年3月期: 業務効率化、コスト削減施策により、売上高比は減少に転じると予測。\n",
        "2028年3月期: 引き続き、業務効率化、コスト削減施策を推進し、売上高比は減少傾向を維持すると予測。\n",
        "営業外収益:\n",
        "\n",
        "預金利息による収益増加を見込む。\n",
        "営業外費用:\n",
        "\n",
        "為替変動による影響を除き、ほぼ横ばいとなると予測。\n",
        "特別利益・特別損失:\n",
        "\n",
        "特に大きな要因がないため、計上しない。\n",
        "法人税等合計:\n",
        "\n",
        "税金等調整前当期純利益の30.62%を計上。\n",
        "留意点:\n",
        "\n",
        "上記の予測は、現時点で入手可能な情報に基づくものであり、実際の業績は、今後の経済状況、市場動向、競争環境等の変化により、大きく異なる可能性があります。\n",
        "特に、競合他社の動向、法規制の変更、社会情勢の変化などが、業績に大きな影響を与える可能性があります。\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YfhVQUFfwWNz"
      },
      "id": "YfhVQUFfwWNz",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_analytic = chain_analytic.invoke(output_pl)"
      ],
      "metadata": {
        "id": "0itKzq82wWQC"
      },
      "id": "0itKzq82wWQC",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_analytic"
      ],
      "metadata": {
        "id": "V1_irFPvwWUm",
        "outputId": "9ba2c9ed-80eb-4e15-b4db-96b54d87fe19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "id": "V1_irFPvwWUm",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'## 1. 使用したデータとその根拠\\n\\n貴社の事業内容が明確でないため、具体的なデータや分析結果を提示することはできません。しかし、サステナビリティ・ESG経営コンサルティングという事業内容を仮定し、収益予測に活用できるデータとその分析例を以下に示します。\\n\\n**1. 業界平均成長 / 市場トレンド:**\\n\\n* **データ:** 経済産業省「グリーン成長戦略」（2021年6月発表）\\n* **分析:**  同戦略では、2050年カーボンニュートラル実現に向け、企業のESG経営への取り組みが不可欠とされています。このことから、ESGコンサルティング市場は、今後数年間は高い成長率が見込まれます。\\n* **出典:** 経済産業省ウェブサイト (https://www.meti.go.jp/policy/energy_environment/global_warming/ggs.html)\\n\\n**2. 市場規模 / 潜在顧客数:**\\n\\n* **データ:**  矢野経済研究所「ESGコンサルティング市場に関する調査」（2023年版）を参考に推定\\n* **分析:**  市場規模や企業数、ESGへの取り組み状況などを分析することで、潜在顧客数を推定することができます。例えば、従業員数1,000人以上の企業のうち、ESGレポートを発行している企業は増加傾向にある一方、未発行の企業もまだ多数存在します。これらの企業は、貴社の潜在顧客となりえます。\\n* **出典:** 矢野経済研究所ウェブサイト (https://www.yano.co.jp/) \\n\\n**3. 競合:**\\n\\n* **データ:** 各社のウェブサイト、企業情報データベース等\\n* **分析:** 競合他社のサービス内容、料金体系、顧客ターゲットなどを分析することで、自社の強み・弱みを明確化し、適切な価格設定や顧客ターゲティングを行うことができます。\\n\\n**4. SWOT分析:**\\n\\n* **データ:** 上記1〜3のデータ、社内資料等\\n* **分析:**  市場機会や競合状況を踏まえ、自社の強み・弱み、機会・脅威を分析することで、今後の事業戦略を策定することができます。例えば、貴社の強みが「経験豊富なコンサルタント」である場合、顧客企業のニーズに合わせた質の高いコンサルティングサービスを提供することで、競争優位性を築くことができます。\\n\\n## 2. 収益予測方法\\n\\n売上高は、主に以下の要素を掛け合わせて算出しています。\\n\\n* **顧客獲得数:** \\n    * 市場規模や競合状況、マーケティング活動の費用対効果などを考慮し、新規顧客獲得数と既存顧客維持率を予測\\n* **顧客単価:** \\n    * サービス内容、契約期間、競合との価格差などを考慮し、顧客一社あたりの平均売上額を予測\\n* **売上増加率:** \\n    * クロスセル、アップセル施策の効果、新規サービス導入による売上貢献などを考慮し、既存顧客からの売上増加率を予測\\n\\n上記以外にも、マクロ経済指標（GDP成長率、設備投資動向など）や業界動向、法規制の変更なども考慮し、売上高を予測しています。\\n\\n## 留意点\\n\\n上記の分析例は、あくまで一例であり、貴社の事業内容や市場環境によって、考慮すべきデータや分析方法は異なります。より精度の高い収益予測を行うためには、詳細な市場調査や競合分析、顧客ニーズの把握などが不可欠です。 \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_fusion = output_analytic + output_pl"
      ],
      "metadata": {
        "id": "N_fRDxaiwWW7"
      },
      "id": "N_fRDxaiwWW7",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_entity = chain_get_name_entity.invoke({\"context\": output_analytic})\n",
        "print(list_entity)"
      ],
      "metadata": {
        "id": "AP6LxjhgwWY6",
        "outputId": "d98ad73e-23e2-43ff-e68a-e2d0629e1cd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "AP6LxjhgwWY6",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['グリーン成長戦略/経済産業省', 'ESGコンサルティング市場/矢野経済研究所', '競合他社', 'SWOT分析', '顧客獲得数', '顧客単価', '売上増加率', 'マクロ経済指標', '業界動向', '法規制の変更']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_question = chain_get_question.invoke({\"list_name_entity\": list_entity, \"context\": output_analytic})\n",
        "print(list_question)\n",
        "print()"
      ],
      "metadata": {
        "id": "aCBYHh91N_XT",
        "outputId": "dda60966-28d6-4a58-ca2f-e01f7c157ba2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aCBYHh91N_XT",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['経済産業省のグリーン成長戦略は、ESGコンサルティング市場の収益予測にどのような影響を与えますか？', '矢野経済研究所のESGコンサルティング市場に関する調査結果に基づいて、潜在顧客数をどのように推定しましたか？', '競合他社の分析は、収益予測においてどのような役割を果たしましたか？', 'SWOT分析は、収益予測の精度向上にどのように役立ちましたか？', 'マクロ経済指標は、ESGコンサルティングの収益予測にどのように考慮されましたか？', '業界動向や法規制の変更は、収益予測にどのような影響を与えましたか？']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_result = \"\"\n",
        "result = []\n",
        "if len(list_question) != 0:\n",
        "  for ques in list_question:\n",
        "    res = chain_search.invoke(ques)\n",
        "    result.append(res)\n",
        "for ind, val in enumerate(result):\n",
        "  # if check_data_output(list_entity[ind], val):\n",
        "  final_result += f\"//***{list_entity[ind]}***//\" + '\\n'\n",
        "  final_result += val['answer'] + \"\\n\" + \"SOURCE: \\n\" + \"\\n\".join(val['context']) + '\\n\\n'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XD15NhcwWbX",
        "outputId": "431e7e62-2998-419e-c484-112913f5557e"
      },
      "id": "7XD15NhcwWbX",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------\n",
            "['snippet: 1．背景. 本年2月に閣議決定された「gx実現に向けた基本方針」（7月に「脱炭素成長型経済構造移行推進戦略（gx推進戦略）」を閣議決定）の参考資料として、国が長期・複数年度にわたるコミットメントを示すと同時に、規制・制度的措置の見通しを示すべく、22分野において「道行き」を提示 ..., title: Gx実現に向けた投資促進策を具体化する「分野別投資戦略」を取りまとめました （Meti/経済産業省）, link: https://www.meti.go.jp/press/2023/12/20231222005/20231222005.html', ' [snippet: グリーン成長戦略とは「2050年カーボンニュートラルを目指す」と宣言をした日本が、2020年10月に策定した計画です。グリーン成長戦略では14重要分野を選定したり、企業の参画を後押しする政策ツールを挙げたりしています。 グリーン成長戦略について、各重要分野を事例とともに分かり ..., title: グリーン成長戦略とは？14の重点分野と取り組み事例も, link: https://spaceshipearth.jp/green-growth-strategy/', ' [snippet: 2050年カーボンニュートラルに伴うグリーン成長戦略. 経済産業省は2021年6月に、「2050年カーボンニュートラルに伴うグリーン成長戦略」を策定しています。この戦略において、2兆円規模のグリーンイノベーション基金の創設やカーボンニュートラルに向けた ..., title: GX（グリーントランスフォーメーション）とは？目的やメリットを解説, link: https://note.com/tci_sdgs/n/nc7ec675b6107', ' [snippet: 経済産業省は、2022年12月に設立した「サステナブルな企業価値創造に向けたサステナビリティ関連データの効率的な収集と戦略的活用に関するワーキング・グループ（WG）」の検討結果を中間整理として、とりまとめました。., title: 「サステナブルな企業価値創造に向けたサステナビリティ関連データの効率的な収集と戦略的活用に関するワーキング・グループ（Wg）」の中間整理を ..., link: https://www.meti.go.jp/press/2023/07/20230718002/20230718002.html']\n",
            "--------------\n",
            "--------------\n",
            "['snippet: 株式会社矢野経済研究所（代表取締役社長：水越孝）は、国内の「オタク」市場を調査し、主要分野における各分野別の動向、参入企業動向、将来展望を明らかにした。ここでは、主要14分野の市場規模について、公表する。, title: 「オタク」市場に関する調査を実施（2023年） | ニュース・トピックス | 市場調査とマーケティングの矢野経済研究所, link: https://www.yano.co.jp/press-release/show/press_id/3383', ' [snippet: 2022年度の企業向け研修サービス市場は前年度比3.1％増の5,370億円、2023年度は同2.4％増の5,500億円を予測. ～人的資本情報開示義務化を背景とした教育投資意欲の高まりが加速する中でプラス成長継続へ～. 株式会社矢野経済研究所（代表取締役社長：水越孝 ..., title: 企業向け研修サービス市場に関する調査を実施（2023年） | ニュース・トピックス | 市場調査とマーケティングの矢野経済研究所, link: https://www.yano.co.jp/press-release/show/press_id/3359', ' [snippet: 【プレスリリース】発表日:2024年07月05日化粧品受託製造市場に関する調査を実施（2024年）2023年度の化粧品受託製造市場は前年度比104.2%の3,456億円 ..., title: 矢野経済研究所、化粧品受託製造市場に関する調査結果を発表 - 日本経済新聞, link: https://www.nikkei.com/article/DGXZRSP674374_V00C24A7000000/', ' [snippet: 株式会社矢野経済研究所（代表取締役社長：水越孝）は、国内の消費者向け（BtoC）サブスクリプションサービス市場を調査し、定期宅配系を除く主要7分野（ファッション分野／飲食店サービス・テイクアウト分野／ライフスタイル分野／レジャー・エンタメ分野／情報コンテンツ分野／教育 ..., title: サブスクリプションサービス市場に関する調査を実施（2023年） | ニュース・トピックス | 市場調査とマーケティングの矢野経済研究所, link: https://www.yano.co.jp/press-release/show/press_id/3416']\n",
            "--------------\n",
            "--------------\n",
            "['snippet: 競合分析を徹底解説：成功するための戦略と実践方法. 2024年6月14日 2024年6月5日. 編集部. 競合分析は、ビジネスの成功に不可欠な戦略の一つです。. 自社と同じ市場で活動する競合他社の動向を把握し、その強みや弱みを分析することで、競争優位性を確保 ..., title: 競合分析を徹底解説：成功するための戦略と実践方法 | Reinforz Insight, link: https://reinforz.co.jp/bizmedia/43451/', ' [snippet: 競合分析後は抽出された強みや課題などを放置せず、stp分析から4pを経て自社の戦略や施策の立案に生かします。 分析の流れ STP分析の具体的なやり方や注意点について知りたい方は、こちらの記事もあわせてチェックしてみてください。, title: 競合分析のやり方を5STEPで解説｜フレームワークから分析項目まで | BeMARKE（ビーマーケ）, link: https://be-marke.jp/articles/knowhow-competitive-analysis', ' [snippet: 競合分析は、自社の市場内での立ち位置を明確にし、競合他社との比較を通じて自社の強みと弱みを理解するプロセスです。. この分析は、戦略的な意思決定に不可欠であり、市場動向の変化に迅速に対応するための洞察を提供します。. 具体的には、競合 ..., title: なぜ競合他社分析がビジネス成功に不可欠なのか？ | 株式会社koujitsu, link: https://koujitsu.co.jp/blogs/competitor-analysis/', ' [snippet: 競合分析のフレームワークでは、競合他社の情報が重要な部分を占めていますが、情報を収集した後は、焦点を自社に戻しましょう。 SWOT 分析 は、自社の強みと弱みを明らかにし、弱みを機会に変え、競合他社の情報をもとに、直面する脅威を評価するのに ..., title: 競合分析のやり方を実例付きで解説 (テンプレート付き) [2024] • Asana, link: https://asana.com/ja/resources/competitive-analysis-example']\n",
            "--------------\n",
            "--------------\n",
            "['snippet: SWOT分析とは、事業やマーケティングの戦略策定のために、自社の現状を多角的に分析するためのフレームワークです。 自社の強みと弱み（内部環境）、市場や競争における機会・脅威（外部環境）の4つの観点から分析することで、自社の市場機会や事業課題を発見します。 本記事ではSWOT分析 ..., title: SWOT分析とは？重要性から分析の進め方、注意点までわかりやすく解説!｜CMS「Blue Monkey」, link: https://bluemonkey.jp/media/column/swat-analysis', ' [snippet: SWOT分析は、経営分析の一種です。強み（Strength）、弱み（Weakness）、機会（Opportunity）、脅威（Threat）の4つのカテゴリーに分けて自社を見つめ直し、マーケティングに活かします。マーケティングをする上で必要不可欠なフレームワークとして知られていますが、なぜ重要なのか、疑問に感じて ..., title: 【事例あり】Swot分析とは？目的や具体的なやり方 | リサーチ・市場調査ならクロス・マーケティング, link: https://www.cross-m.co.jp/column/marketing/mkc20240531/', ' [snippet: 「SWOT分析」は、「強み」、「弱み」、「機会」、「脅威」という4つの要素を分析することで、経営戦略や事業計画の現状を把握するフレームワークだ。人事戦略で活用すれば、採用プロセスの改善や人材育成の方向性の設定など、さまざまな業務の質を高めることができる。そこで本稿では ..., title: 【図解で解説】Swot分析とは？ やり方や企業の分析例を解説 | 人事のプロを支援するhrプロ, link: https://www.hrpro.co.jp/series_detail.php?t_no=3962', ' [snippet: 1-1．SWOT分析とは. SWOT分析とは、企業や事業の現状を強み・弱み・機会・脅威という4つの観点から分析するためのフレームワーク です。. SWOTはそれぞれの観点の頭文字を取ったもので、下記のように分類されています。. 強み (Strength)：内部環境×プラス要因 ..., title: 図解でわかる!Swot分析とは？分析の進め方と事例6選を紹介 - 新規事業とマーケティング支援のミモズカンパニー, link: https://mimorenko.net/media/archives/2075']\n",
            "--------------\n",
            "--------------\n",
            "['snippet: EYのESGモデルは、ESG KPIと企業価値（または株式価値）との間にどのような関係があるのかを定量的に解析します。. 企業価値（または株式価値）の定量化のためには以下の2つのアプローチが考えられます。. 1.「PBR」や「PER」といった株式市場での 直接的 な ..., title: ESGと企業価値の定量分析（EYのESGモデルの紹介）, link: https://www.ey.com/ja_jp/strategy-transactions/info-sensor-2024-05-05-trend-watcher', ' [snippet: ESG経営は、環境・社会・ガバナンスの3つの要素を重視する経営方法、概念を表す言葉です。. 近年では社会情勢の先行きを予測することが難しくなり、投資家も投資の際の指針としてESG経営を重要視するようになりました。. ESG経営に取り組むことで企業 ..., title: Esg経営とは？ 意味やメリット・事例などを解説 | 株式会社 日立ソリューションズ・クリエイト, link: https://www.hitachi-solutions-create.co.jp/column/management-strategy/esg.html', ' [snippet: ESGコンサルタントは、企業や投資家が持続可能な経営や投資戦略を構築する際に重要な役割を果たしています。. 主な役割は、以下の4点が挙げられます。. 1. ESG戦略の策定とアドバイス. 企業や投資家に対して適切なESG戦略を策定するためのアドバイスを提供 ..., title: ESGコンサルタントとは？役割や仕事内容、求められるスキルを解説｜タナベコンサルティングの長期ビジョン策定支援, link: https://www.tanabeconsulting.co.jp/vision/column/detail113.html', ' [snippet: グローバル化の進展によって、1つの地域や国の問題に留まらない共通の課題が多い現代において、投資行動と企業実務の双方で重要度が高まっているキーワードが「ESG」です。本記事ではそんなESGの意味と背景を解説するとともに、その取り組み事例とESGを意識した経営手法の導入ステップを ..., title: Esgとは？企業の取組事例やesg経営導入ステップをわかりやすく解説 | Doors Dx, link: https://www.brainpad.co.jp/doors/contents/about_esg/']\n",
            "--------------\n",
            "--------------\n",
            "['snippet: スマートフォンの分野で優越的な地位にある巨大IT企業を規制するための新たな法律が12日の参議院本会議で可決・成立しました。. 法律では競争 ..., title: 巨大it企業を規制の新法 参院本会議で可決・成立 | Nhk | It・ネット, link: https://www3.nhk.or.jp/news/html/20240612/k10014478361000.html', ' [snippet: 近年は、ECサイトの利用が拡大したことで、物流量も増加しています。. 2024年4月1日から時間外労働の上限規制が適用された場合、物流が停滞してしまう可能性があります。. 国土交通省の発表によると、規制に対して具体的な対応を取らなかった場合、2024 ..., title: 物流の2024年問題│背景や業界への影響と取るべき解決策を解説 | 三菱倉庫株式会社, link: https://service.mitsubishi-logistics.co.jp/column/05', ' [snippet: 2024年1月22日、中国の独占禁止法に基づき事業者集中の届出が必要となる基準を定める、「国務院による事業者集中の届出基準に関する規定」が公布・施行されました。. 本改正では、この届出基準について、従前よりも事業者の売上高の基準値が大幅に ..., title: 2024年3月に押さえておくべき企業法務の最新動向 - Business Lawyers, link: https://www.businesslawyers.jp/articles/1366', ' [snippet: 2024年問題に直面する運送業界の最新動向と改正法案の概要をまとめたコラムです。荷主・物流事業者、トラック事業者、軽トラック事業者に対する新規制の紹介と、これらが物流業界に与える影響について詳しく解説しています。運送業界の持続的成長と効率化を目指す重要な情報を提供します。, title: 【続報】運送業界における2024年問題についての最新動向まとめ（2024年2月末時点）, link: https://commoncom.jp/column/zoku_2024.html']\n",
            "--------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_result)"
      ],
      "metadata": {
        "id": "4JHSKqdV9hQ0",
        "outputId": "d9735fed-82f2-498f-f5ac-803689b2a460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4JHSKqdV9hQ0",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "//***グリーン成長戦略/経済産業省***//\n",
            "申し訳ありませんが、提供されたスニペットとタイトルには、財務および社会分析、または年ごとの財務数値に関する情報が含まれていません。したがって、要求された詳細な説明を提供することはできません。 \n",
            "\n",
            "SOURCE: \n",
            "Gx実現に向けた投資促進策を具体化する「分野別投資戦略」を取りまとめました （Meti/経済産業省）, \n",
            "https://www.meti.go.jp/press/2023/12/20231222005/20231222005.html\n",
            "グリーン成長戦略とは？14の重点分野と取り組み事例も, \n",
            "https://spaceshipearth.jp/green-growth-strategy/\n",
            "GX（グリーントランスフォーメーション）とは？目的やメリットを解説, \n",
            "https://note.com/tci_sdgs/n/nc7ec675b6107\n",
            "「サステナブルな企業価値創造に向けたサステナビリティ関連データの効率的な収集と戦略的活用に関するワーキング・グループ（Wg）」の中間整理を ..., \n",
            "https://www.meti.go.jp/press/2023/07/20230718002/20230718002.html\n",
            "\n",
            "//***ESGコンサルティング市場/矢野経済研究所***//\n",
            "このスニペットからは、詳細な財務データや社会分析を引き出すことはできません。矢野経済研究所のプレスリリースからの抜粋であり、市場規模や成長率といった断片的な情報しか提供されていません。\n",
            "\n",
            "詳細な財務数値や社会分析を得るには、矢野経済研究所の調査レポートを購入するか、各市場セグメントに関する詳細な情報を提供する他の情報源を参照する必要があります。 \n",
            "\n",
            "SOURCE: \n",
            "「オタク」市場に関する調査を実施（2023年） | ニュース・トピックス | 市場調査とマーケティングの矢野経済研究所, \n",
            "https://www.yano.co.jp/press-release/show/press_id/3383\n",
            "企業向け研修サービス市場に関する調査を実施（2023年） | ニュース・トピックス | 市場調査とマーケティングの矢野経済研究所, \n",
            "https://www.yano.co.jp/press-release/show/press_id/3359\n",
            "矢野経済研究所、化粧品受託製造市場に関する調査結果を発表 - 日本経済新聞, \n",
            "https://www.nikkei.com/article/DGXZRSP674374_V00C24A7000000/\n",
            "サブスクリプションサービス市場に関する調査を実施（2023年） | ニュース・トピックス | 市場調査とマーケティングの矢野経済研究所, \n",
            "https://www.yano.co.jp/press-release/show/press_id/3416\n",
            "\n",
            "//***競合他社***//\n",
            "申し訳ありませんが、提供されたテキストスニペットには、財務および社会分析、または年ごとの財務数値に関する情報は含まれていません。したがって、質問に答えることはできません。 \n",
            "\n",
            "SOURCE: \n",
            "競合分析を徹底解説：成功するための戦略と実践方法 | Reinforz Insight, \n",
            "https://reinforz.co.jp/bizmedia/43451/\n",
            "競合分析のやり方を5STEPで解説｜フレームワークから分析項目まで | BeMARKE（ビーマーケ）, \n",
            "https://be-marke.jp/articles/knowhow-competitive-analysis\n",
            "なぜ競合他社分析がビジネス成功に不可欠なのか？ | 株式会社koujitsu, \n",
            "https://koujitsu.co.jp/blogs/competitor-analysis/\n",
            "競合分析のやり方を実例付きで解説 (テンプレート付き) [2024] • Asana, \n",
            "https://asana.com/ja/resources/competitive-analysis-example\n",
            "\n",
            "//***SWOT分析***//\n",
            "申し訳ありませんが、提供されたテキストには、財務および社会分析、または年ごとの財務数値に関する情報が含まれていません。したがって、要求された詳細な説明を提供することはできません。 \n",
            "\n",
            "SOURCE: \n",
            "SWOT分析とは？重要性から分析の進め方、注意点までわかりやすく解説!｜CMS「Blue Monkey」, \n",
            "https://bluemonkey.jp/media/column/swat-analysis\n",
            "【事例あり】Swot分析とは？目的や具体的なやり方 | リサーチ・市場調査ならクロス・マーケティング, \n",
            "https://www.cross-m.co.jp/column/marketing/mkc20240531/\n",
            "【図解で解説】Swot分析とは？ やり方や企業の分析例を解説 | 人事のプロを支援するhrプロ, \n",
            "https://www.hrpro.co.jp/series_detail.php?t_no=3962\n",
            "図解でわかる!Swot分析とは？分析の進め方と事例6選を紹介 - 新規事業とマーケティング支援のミモズカンパニー, \n",
            "https://mimorenko.net/media/archives/2075\n",
            "\n",
            "//***顧客獲得数***//\n",
            "提供されたテキストスニペットは、ESGと企業価値の関係について、具体的な財務分析や数値データを示したものではありません。そのため、質問に対する回答を提供できません。 \n",
            "\n",
            "テキストスニペットは、ESG経営の定義、メリット、コンサルタントの役割、導入ステップなどを解説するものであり、財務数値を用いた詳細な分析は含まれていません。 \n",
            "\n",
            "SOURCE: \n",
            "ESGと企業価値の定量分析（EYのESGモデルの紹介）, \n",
            "https://www.ey.com/ja_jp/strategy-transactions/info-sensor-2024-05-05-trend-watcher\n",
            "Esg経営とは？ 意味やメリット・事例などを解説 | 株式会社 日立ソリューションズ・クリエイト, \n",
            "https://www.hitachi-solutions-create.co.jp/column/management-strategy/esg.html\n",
            "ESGコンサルタントとは？役割や仕事内容、求められるスキルを解説｜タナベコンサルティングの長期ビジョン策定支援, \n",
            "https://www.tanabeconsulting.co.jp/vision/column/detail113.html\n",
            "Esgとは？企業の取組事例やesg経営導入ステップをわかりやすく解説 | Doors Dx, \n",
            "https://www.brainpad.co.jp/doors/contents/about_esg/\n",
            "\n",
            "//***顧客単価***//\n",
            "The provided context discusses new regulations aimed at tech giants, logistics industry challenges in 2024 due to labor law changes, and China's updated anti-monopoly law. However, there is **no specific financial or societal analysis request** within the context. \n",
            "\n",
            "To provide a relevant financial and societal analysis with yearly financial figures, please provide:\n",
            "\n",
            "1. **Specific focus:** Which aspect needs analysis? (e.g., financial impact of tech regulations on a specific company, societal impact of logistics disruption)\n",
            "2. **Target year(s):**  For which years do you need financial figures?\n",
            "\n",
            "Once you provide these details, I can generate a comprehensive analysis. \n",
            "\n",
            "SOURCE: \n",
            "巨大it企業を規制の新法 参院本会議で可決・成立 | Nhk | It・ネット, \n",
            "https://www3.nhk.or.jp/news/html/20240612/k10014478361000.html\n",
            "物流の2024年問題│背景や業界への影響と取るべき解決策を解説 | 三菱倉庫株式会社, \n",
            "https://service.mitsubishi-logistics.co.jp/column/05\n",
            "2024年3月に押さえておくべき企業法務の最新動向 - Business Lawyers, \n",
            "https://www.businesslawyers.jp/articles/1366\n",
            "【続報】運送業界における2024年問題についての最新動向まとめ（2024年2月末時点）, \n",
            "https://commoncom.jp/column/zoku_2024.html\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pgbzanyd9i8w"
      },
      "id": "Pgbzanyd9i8w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Fiq0C6g9i-x"
      },
      "id": "4Fiq0C6g9i-x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zeNB_yfM9hUN"
      },
      "id": "zeNB_yfM9hUN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I2W3v8Ys9hWa"
      },
      "id": "I2W3v8Ys9hWa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xochjeJSwWgE"
      },
      "id": "xochjeJSwWgE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g5YdSUCUykdd"
      },
      "id": "g5YdSUCUykdd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_search_api_X = \"\"\"\n",
        "文脈に基づいて\n",
        "  1. {context}\n",
        "  2. 質問 {question} の回答を検索した後に DuckDuckGoSearch で見つかったスニペット, {snippets}\n",
        "関連する財務および社会分析。より詳細な説明を提供し、各年の財務数値を示して説明し、{context} を正当化してください。\n",
        "注:\n",
        "1. 回答は日本語でなければなりません。\n",
        "2. 質問を繰り返したり、要求された以上の情報を尋ねたりしないでください。\n",
        "3. 質問に答える記事がない場合、または回答がない場合、結果は表示されません。\n",
        "\"\"\"\n",
        "parser_question = JsonOutputParser(pydantic_object=OutputNameEntity)\n",
        "\n",
        "prompt_get_question= PromptTemplate(\n",
        "    template=template_search_api_X,\n",
        "    input_variables=[\"snippets\"],\n",
        "    partial_variables={\"format_instructions\": parser_question.get_format_instructions()},\n",
        ")\n",
        "\n",
        "prompt_search_api = PromptTemplate.from_template(template_search_api)"
      ],
      "metadata": {
        "id": "ukoPD2JSykgn"
      },
      "id": "ukoPD2JSykgn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_search.invoke(\"\"\"2022年3月期実績 \"\"\" )"
      ],
      "metadata": {
        "id": "BA5bxNX3wWia",
        "outputId": "56a414e0-e679-4dbb-8942-125343635738",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BA5bxNX3wWia",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------\n",
            "['snippet: 決算情報 （2024年5月8日）. 決算要旨. 決算報告プレゼンテーション資料. 決算報告プレゼンテーション資料（スクリプト付き）. 決算説明会（佐藤社長メッセージ）スピーチ. 決算説明会（佐藤社長メッセージ）資料. メディア向け決算説明会の模様をご覧 ..., title: 決算報告 | 投資家情報 | トヨタ自動車株式会社 公式企業サイト, link: https://global.toyota/jp/ir/financial-results/', ' [snippet: 2021年3月期および2022年3月期の第2四半期の配当金の額は、当該株式分割前の実績の配当金の額を記載しています。 2022年3月期の年間配当金については、株式分割の実施により単純合算ができないため、表示していません。, title: 7203 トヨタ自動車 | 配当金の推移 - Ir Bank, link: https://irbank.net/E02144/dividend', ' [snippet: 株式会社東京証券取引所 株式部データサービス室. 電話：050-3377-7774. E-mail： databank-geppou@jpx.co.jp. 日本取引所グループ（JPX）は、東京証券取引所、大阪取引所、東京商品取引所等を運営する取引所グループです。. 総合的なサービス提供を行うことで、市場 ..., title: 調査レポート | 日本取引所グループ, link: https://www.jpx.co.jp/markets/statistics-equities/examination/', ' [snippet: 2025年3月期通期見通し（セグメント別当期純利益） 2024年4月1日付の組織変更に伴い、「航空・社会インフラ本部」「エネルギー・ヘルスケア本部」「その他」については、旧組織を簡便的に新組織に組み替えたものであり、将来公表する数値とは異なる可能 ..., title: 直近の業績と見通し｜業績・財務｜IR情報（投資家情報）｜双日株式会社, link: https://www.sojitz.com/jp/ir/highlights/latest/']\n",
            "--------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'question': '2022年3月期実績 ',\n",
              " 'docs': '[snippet: 決算情報 （2024年5月8日）. 決算要旨. 決算報告プレゼンテーション資料. 決算報告プレゼンテーション資料（スクリプト付き）. 決算説明会（佐藤社長メッセージ）スピーチ. 決算説明会（佐藤社長メッセージ）資料. メディア向け決算説明会の模様をご覧 ..., title: 決算報告 | 投資家情報 | トヨタ自動車株式会社 公式企業サイト, link: https://global.toyota/jp/ir/financial-results/], [snippet: 2021年3月期および2022年3月期の第2四半期の配当金の額は、当該株式分割前の実績の配当金の額を記載しています。 2022年3月期の年間配当金については、株式分割の実施により単純合算ができないため、表示していません。, title: 7203 トヨタ自動車 | 配当金の推移 - Ir Bank, link: https://irbank.net/E02144/dividend], [snippet: 株式会社東京証券取引所 株式部データサービス室. 電話：050-3377-7774. E-mail： databank-geppou@jpx.co.jp. 日本取引所グループ（JPX）は、東京証券取引所、大阪取引所、東京商品取引所等を運営する取引所グループです。. 総合的なサービス提供を行うことで、市場 ..., title: 調査レポート | 日本取引所グループ, link: https://www.jpx.co.jp/markets/statistics-equities/examination/], [snippet: 2025年3月期通期見通し（セグメント別当期純利益） 2024年4月1日付の組織変更に伴い、「航空・社会インフラ本部」「エネルギー・ヘルスケア本部」「その他」については、旧組織を簡便的に新組織に組み替えたものであり、将来公表する数値とは異なる可能 ..., title: 直近の業績と見通し｜業績・財務｜IR情報（投資家情報）｜双日株式会社, link: https://www.sojitz.com/jp/ir/highlights/latest/]',\n",
              " 'snippets': ('snippet: 決算情報 （2024年5月8日）. 決算要旨. 決算報告プレゼンテーション資料. 決算報告プレゼンテーション資料（スクリプト付き）. 決算説明会（佐藤社長メッセージ）スピーチ. 決算説明会（佐藤社長メッセージ）資料. メディア向け決算説明会の模様をご覧 ..., snippet: 2021年3月期および2022年3月期の第2四半期の配当金の額は、当該株式分割前の実績の配当金の額を記載しています。 2022年3月期の年間配当金については、株式分割の実施により単純合算ができないため、表示していません。, snippet: 株式会社東京証券取引所 株式部データサービス室. 電話：050-3377-7774. E-mail： databank-geppou@jpx.co.jp. 日本取引所グループ（JPX）は、東京証券取引所、大阪取引所、東京商品取引所等を運営する取引所グループです。. 総合的なサービス提供を行うことで、市場 ..., snippet: 2025年3月期通期見通し（セグメント別当期純利益） 2024年4月1日付の組織変更に伴い、「航空・社会インフラ本部」「エネルギー・ヘルスケア本部」「その他」については、旧組織を簡便的に新組織に組み替えたものであり、将来公表する数値とは異なる可能 ..., ',\n",
              "  'title: 決算報告 | 投資家情報 | トヨタ自動車株式会社 公式企業サイト, title: 7203 トヨタ自動車 | 配当金の推移 - Ir Bank, title: 調査レポート | 日本取引所グループ, title: 直近の業績と見通し｜業績・財務｜IR情報（投資家情報）｜双日株式会社, '),\n",
              " 'answer': '申し訳ありませんが、提示された情報だけでは、財務および社会分析を提供したり、詳細な財務数値を説明したりすることはできません。\\n\\nスニペットはトヨタ自動車、Ir Bank、日本取引所グループ、双日株式会社のウェブサイトからの抜粋のようです。これらは財務情報を含む可能性のあるページですが、断片的な情報だけでは包括的な分析や財務数値の説明は不可能です。\\n\\n詳細な財務および社会分析を行うには、各企業の財務諸表（貸借対照表、損益計算書、キャッシュフロー計算書など）、サステナビリティレポート、およびその他の関連資料を精査する必要があります。 \\n',\n",
              " 'context': ['決算報告 | 投資家情報 | トヨタ自動車株式会社 公式企業サイト, ',\n",
              "  'https://global.toyota/jp/ir/financial-results/']}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SjaoFONVwWk7"
      },
      "id": "SjaoFONVwWk7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YSEYBLjSwWnq"
      },
      "id": "YSEYBLjSwWnq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJYXA87QwWqO"
      },
      "id": "pJYXA87QwWqO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HY-1FJu3wWs6"
      },
      "id": "HY-1FJu3wWs6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "to7yLOPYwWvS"
      },
      "id": "to7yLOPYwWvS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sxw1Khp-wWx6"
      },
      "id": "sxw1Khp-wWx6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NGuvefl_wW0j"
      },
      "id": "NGuvefl_wW0j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v8Eb4RkqwW3S"
      },
      "id": "v8Eb4RkqwW3S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78QTW9E7wW51"
      },
      "id": "78QTW9E7wW51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Eaz-9wXwW8t"
      },
      "id": "8Eaz-9wXwW8t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "os4W9UfawW_K"
      },
      "id": "os4W9UfawW_K",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CBl-BvGtwXBq"
      },
      "id": "CBl-BvGtwXBq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ipXjrKR5wXEb"
      },
      "id": "ipXjrKR5wXEb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-lUiSI9wXHE"
      },
      "id": "d-lUiSI9wXHE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mwnPDUqtwXJc"
      },
      "id": "mwnPDUqtwXJc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nfdBB3VDwXOj"
      },
      "id": "nfdBB3VDwXOj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YJLbtifCwXVi"
      },
      "id": "YJLbtifCwXVi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7a4ba72d",
      "metadata": {
        "id": "7a4ba72d"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/02-langchain-chains.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/02-langchain-chains.ipynb)\n",
        "\n",
        "#### [LangChain Handbook](https://github.com/pinecone-io/examples/tree/master/generation/langchain/handbook)\n",
        "\n",
        "# Getting Started with Chains\n",
        "\n",
        "Chains are the core of LangChain. They are simply a chain of components, executed in a particular order.\n",
        "\n",
        "The simplest of these chains is the `LLMChain`. It works by taking a user's input, passing in to the first element in the chain — a `PromptTemplate` — to format the input into a particular prompt. The formatted prompt is then passed to the next (and final) element in the chain — a LLM.\n",
        "\n",
        "We'll start by importing all the libraries that we'll be using in this example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66fb9c2a",
      "metadata": {
        "id": "66fb9c2a"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "import re\n",
        "\n",
        "from getpass import getpass\n",
        "from langchain import OpenAI, PromptTemplate\n",
        "from langchain.chains import LLMChain, LLMMathChain, TransformChain, SequentialChain\n",
        "from langchain.callbacks import get_openai_callback"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wPdWz1IdxyBR",
      "metadata": {
        "id": "wPdWz1IdxyBR"
      },
      "source": [
        "To run this notebook, we will need to use an OpenAI LLM. Here we will setup the LLM we will use for the whole notebook, just input your openai api key when prompted."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v86cmyppxdfc",
      "metadata": {
        "id": "v86cmyppxdfc"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = getpass()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "baaa74b8",
      "metadata": {
        "id": "baaa74b8"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(\n",
        "    temperature=0,\n",
        "    openai_api_key=OPENAI_API_KEY\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "309g_2pqxzzB",
      "metadata": {
        "id": "309g_2pqxzzB"
      },
      "source": [
        "An extra utility we will use is this function that will tell us how many tokens we are using in each call. This is a good practice that is increasingly important as we use more complex tools that might make several calls to the API (like agents). It is very important to have a close control of how many tokens we are spending to avoid unsuspected expenditures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DsC3szr6yP3L",
      "metadata": {
        "id": "DsC3szr6yP3L"
      },
      "outputs": [],
      "source": [
        "def count_tokens(chain, query):\n",
        "    with get_openai_callback() as cb:\n",
        "        result = chain.run(query)\n",
        "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e1f31b4",
      "metadata": {
        "id": "6e1f31b4"
      },
      "source": [
        "## What are chains anyway?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b919c3a",
      "metadata": {
        "id": "5b919c3a"
      },
      "source": [
        "**Definition**: Chains are one of the fundamental building blocks of this lib (as you can guess!).\n",
        "\n",
        "The official definition of chains is the following:\n",
        "\n",
        "\n",
        "> A chain is made up of links, which can be either primitives or other chains. Primitives can be either prompts, llms, utils, or other chains.\n",
        "\n",
        "\n",
        "So a chain is basically a pipeline that processes an input by using a specific combination of primitives. Intuitively, it can be thought of as a 'step' that performs a certain set of operations on an input and returns the result. They can be anything from a prompt-based pass through a LLM to applying a Python function to an text."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4644b2f",
      "metadata": {
        "id": "c4644b2f"
      },
      "source": [
        "Chains are divided in three types: Utility chains, Generic chains and Combine Documents chains. In this edition, we will focus on the first two since the third is too specific (will be covered in due course).\n",
        "\n",
        "1. Utility Chains: chains that are usually used to extract a specific answer from a llm with a very narrow purpose and are ready to be used out of the box.\n",
        "2. Generic Chains: chains that are used as building blocks for other chains but cannot be used out of the box on their own."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d283b6",
      "metadata": {
        "id": "e4d283b6"
      },
      "source": [
        "Let's take a peek into what these chains have to offer!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "831827b7",
      "metadata": {
        "id": "831827b7"
      },
      "source": [
        "### Utility Chains"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c66e4b4",
      "metadata": {
        "id": "6c66e4b4"
      },
      "source": [
        "Let's start with a simple utility chain. The `LLMMathChain` gives llms the ability to do math. Let's see how it works!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HF3XCWD2sVi0",
      "metadata": {
        "id": "HF3XCWD2sVi0"
      },
      "source": [
        "#### Pro-tip: use `verbose=True` to see what the different steps in the chain are!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4161561",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4161561",
        "outputId": "16486831-80a5-41df-906e-376575b7f514"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
            "What is 13 raised to the .3432 power?\u001b[32;1m\u001b[1;3m\n",
            "```python\n",
            "import math\n",
            "print(math.pow(13, .3432))\n",
            "```\n",
            "\u001b[0m\n",
            "Answer: \u001b[33;1m\u001b[1;3m2.4116004626599237\n",
            "\u001b[0m\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Spent a total of 272 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Answer: 2.4116004626599237\\n'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_math = LLMMathChain(llm=llm, verbose=True)\n",
        "\n",
        "count_tokens(llm_math, \"What is 13 raised to the .3432 power?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "198eebb2",
      "metadata": {
        "id": "198eebb2"
      },
      "source": [
        "Let's see what is going on here. The chain recieved a question in natural language and sent it to the llm. The llm returned a Python code which the chain compiled to give us an answer. A few questions arise.. How did the llm know that we wanted it to return Python code?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7a0821a",
      "metadata": {
        "id": "a7a0821a"
      },
      "source": [
        "**Enter prompts**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c86c5798",
      "metadata": {
        "id": "c86c5798"
      },
      "source": [
        "The question we send as input to the chain is not the only input that the llm recieves 😉. The input is inserted into a wider context, which gives precise instructions on how to interpret the input we send. This is called a _prompt_. Let's see what this chain's prompt is!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62778ef4",
      "metadata": {
        "id": "62778ef4",
        "outputId": "211670a8-db56-4f68-d873-97d279870890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are GPT-3, and you can't do math.\n",
            "\n",
            "You can do basic math, and your memorization abilities are impressive, but you can't do any complex calculations that a human could not do in their head. You also have an annoying tendency to just make up highly specific, but wrong, answers.\n",
            "\n",
            "So we hooked you up to a Python 3 kernel, and now you can execute code. If anyone gives you a hard math problem, just use this format and we’ll take care of the rest:\n",
            "\n",
            "Question: ${{Question with hard calculation.}}\n",
            "```python\n",
            "${{Code that prints what you need to know}}\n",
            "```\n",
            "```output\n",
            "${{Output of your code}}\n",
            "```\n",
            "Answer: ${{Answer}}\n",
            "\n",
            "Otherwise, use this simpler format:\n",
            "\n",
            "Question: ${{Question without hard calculation}}\n",
            "Answer: ${{Answer}}\n",
            "\n",
            "Begin.\n",
            "\n",
            "Question: What is 37593 * 67?\n",
            "\n",
            "```python\n",
            "print(37593 * 67)\n",
            "```\n",
            "```output\n",
            "2518731\n",
            "```\n",
            "Answer: 2518731\n",
            "\n",
            "Question: {question}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(llm_math.prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "708031d8",
      "metadata": {
        "id": "708031d8"
      },
      "source": [
        "Ok.. let's see what we got here. So, we are literally telling the llm that for complex math problems **it should not try to do math on its own** but rather it should print a Python code that will calculate the math problem instead. Probably, if we just sent the query without any context, the llm would try (and fail) to calculate this on its own. Wait! This is testable.. let's try it out! 🧐"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66b92768",
      "metadata": {
        "id": "66b92768",
        "outputId": "6c9b7f59-529d-409e-8562-5a622f326473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spent a total of 17 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\n\\n2.907'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we set the prompt to only have the question we ask\n",
        "prompt = PromptTemplate(input_variables=['question'], template='{question}')\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
        "\n",
        "# we ask the llm for the answer with no context\n",
        "\n",
        "count_tokens(llm_chain, \"What is 13 raised to the .3432 power?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d147e7bf",
      "metadata": {
        "id": "d147e7bf"
      },
      "source": [
        "Wrong answer! Herein lies the power of prompting and one of our most important insights so far:\n",
        "\n",
        "**Insight**: _by using prompts intelligently, we can force the llm to avoid common pitfalls by explicitly and purposefully programming it to behave in a certain way._"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cd2a31f",
      "metadata": {
        "id": "1cd2a31f"
      },
      "source": [
        "Another interesting point about this chain is that it not only runs an input through the llm but it later compiles Python code. Let's see exactly how this works."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3488c5b6",
      "metadata": {
        "id": "3488c5b6",
        "outputId": "8b32a998-8e11-48bf-f21c-f5d086186508"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
            "        llm_executor = LLMChain(prompt=self.prompt, llm=self.llm)\n",
            "        python_executor = PythonREPL()\n",
            "        self.callback_manager.on_text(inputs[self.input_key], verbose=self.verbose)\n",
            "        t = llm_executor.predict(question=inputs[self.input_key], stop=[\"```output\"])\n",
            "        self.callback_manager.on_text(t, color=\"green\", verbose=self.verbose)\n",
            "        t = t.strip()\n",
            "        if t.startswith(\"```python\"):\n",
            "            code = t[9:-4]\n",
            "            output = python_executor.run(code)\n",
            "            self.callback_manager.on_text(\"\\nAnswer: \", verbose=self.verbose)\n",
            "            self.callback_manager.on_text(output, color=\"yellow\", verbose=self.verbose)\n",
            "            answer = \"Answer: \" + output\n",
            "        elif t.startswith(\"Answer:\"):\n",
            "            answer = t\n",
            "        else:\n",
            "            raise ValueError(f\"unknown format from LLM: {t}\")\n",
            "        return {self.output_key: answer}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(inspect.getsource(llm_math._call))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa6b6c2e",
      "metadata": {
        "id": "fa6b6c2e"
      },
      "source": [
        "So we can see here that if the llm returns Python code we will compile it with a Python REPL* simulator. We now have the full picture of the chain: either the llm returns an answer (for simple math problems) or it returns Python code which we compile for an exact answer to harder problems. Smart!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67f96bd3",
      "metadata": {
        "id": "67f96bd3"
      },
      "source": [
        "Also notice that here we get our first example of **chain composition**, a key concept behind what makes langchain special. We are using the `LLMMathChain` which in turn initializes and uses an `LLMChain` (a 'Generic Chain') when called. We can make any arbitrary number of such compositions, effectively 'chaining' many such chains to achieve highly complex and customizable behaviour."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b109619a",
      "metadata": {
        "id": "b109619a"
      },
      "source": [
        "Utility chains usually follow this same basic structure: there is a prompt for constraining the llm to return a very specific type of response from a given query. We can ask the llm to create SQL queries, API calls and even create Bash commands on the fly 🔥\n",
        "\n",
        "The list continues to grow as langchain becomes more and more flexible and powerful so we encourage you to [check it out](https://langchain.readthedocs.io/en/latest/modules/chains/utility_how_to.html) and tinker with the example notebooks that you might find interesting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381e329c",
      "metadata": {
        "id": "381e329c"
      },
      "source": [
        "*_A Python REPL (Read-Eval-Print Loop) is an interactive shell for executing Python code line by line_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f66a25a2",
      "metadata": {
        "id": "f66a25a2"
      },
      "source": [
        "### Generic chains"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70b32a84",
      "metadata": {
        "id": "70b32a84"
      },
      "source": [
        "There are only three Generic Chains in langchain and we will go all in to showcase them all in the same example. Let's go!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b8e2048",
      "metadata": {
        "id": "4b8e2048"
      },
      "source": [
        "Say we have had experience of getting dirty input texts. Specifically, as we know, llms charge us by the number of tokens we use and we are not happy to pay extra when the input has extra characters. Plus its not neat 😉"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6e778d2",
      "metadata": {
        "id": "a6e778d2"
      },
      "source": [
        "First, we will build a custom transform function to clean the spacing of our texts. We will then use this function to build a chain where we input our text and we expect a clean text as output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c794e00a",
      "metadata": {
        "id": "c794e00a"
      },
      "outputs": [],
      "source": [
        "def transform_func(inputs: dict) -> dict:\n",
        "    text = inputs[\"text\"]\n",
        "\n",
        "    # replace multiple new lines and multiple spaces with a single one\n",
        "    text = re.sub(r'(\\r\\n|\\r|\\n){2,}', r'\\n', text)\n",
        "    text = re.sub(r'[ \\t]+', ' ', text)\n",
        "\n",
        "    return {\"output_text\": text}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42dc1ac6",
      "metadata": {
        "id": "42dc1ac6"
      },
      "source": [
        "Importantly, when we initialize the chain we do not send an llm as an argument. As you can imagine, not having an llm makes this chain's abilities much weaker than the example we saw earlier. However, as we will see next, combining this chain with other chains can give us highly desirable results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "286f7295",
      "metadata": {
        "id": "286f7295"
      },
      "outputs": [],
      "source": [
        "clean_extra_spaces_chain = TransformChain(input_variables=[\"text\"], output_variables=[\"output_text\"], transform=transform_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977bf11a",
      "metadata": {
        "id": "977bf11a",
        "outputId": "8d6eaa5e-b417-4c17-a345-7b7e32071430"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A random text with some irregular spacing.\\n Another one here as well.'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_extra_spaces_chain.run('A random text  with   some irregular spacing.\\n\\n\\n     Another one   here as well.')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3f84cd0",
      "metadata": {
        "id": "b3f84cd0"
      },
      "source": [
        "Great! Now things will get interesting.\n",
        "\n",
        "Say we want to use our chain to clean an input text and then paraphrase the input in a specific style, say a poet or a policeman. As we now know, the `TransformChain` does not use a llm so the styling will have to be done elsewhere. That's where our `LLMChain` comes in. We know about this chain already and we know that we can do cool things with smart prompting so let's take a chance!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b77042a",
      "metadata": {
        "id": "5b77042a"
      },
      "source": [
        "First we will build the prompt template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73719a5d",
      "metadata": {
        "id": "73719a5d"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"Paraphrase this text:\n",
        "\n",
        "{output_text}\n",
        "\n",
        "In the style of a {style}.\n",
        "\n",
        "Paraphrase: \"\"\"\n",
        "prompt = PromptTemplate(input_variables=[\"style\", \"output_text\"], template=template)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83b2ec83",
      "metadata": {
        "id": "83b2ec83"
      },
      "source": [
        "And next, initialize our chain:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a067ab",
      "metadata": {
        "id": "48a067ab"
      },
      "outputs": [],
      "source": [
        "style_paraphrase_chain = LLMChain(llm=llm, prompt=prompt, output_key='final_output')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2324005d",
      "metadata": {
        "id": "2324005d"
      },
      "source": [
        "Great! Notice that the input text in the template is called 'output_text'. Can you guess why?\n",
        "\n",
        "We are going to pass the output of the `TransformChain` to the `LLMChain`!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5da4925",
      "metadata": {
        "id": "c5da4925"
      },
      "source": [
        "Finally, we need to combine them both to work as one integrated chain. For that we will use `SequentialChain` which is our third generic chain building block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f51f17",
      "metadata": {
        "id": "06f51f17"
      },
      "outputs": [],
      "source": [
        "sequential_chain = SequentialChain(chains=[clean_extra_spaces_chain, style_paraphrase_chain], input_variables=['text', 'style'], output_variables=['final_output'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f0f51d8",
      "metadata": {
        "id": "7f0f51d8"
      },
      "source": [
        "Our input is the langchain docs description of what chains are but dirty with some extra spaces all around."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8032489",
      "metadata": {
        "id": "a8032489"
      },
      "outputs": [],
      "source": [
        "input_text = \"\"\"\n",
        "Chains allow us to combine multiple\n",
        "\n",
        "\n",
        "components together to create a single, coherent application.\n",
        "\n",
        "For example, we can create a chain that takes user input,       format it with a PromptTemplate,\n",
        "\n",
        "and then passes the formatted response to an LLM. We can build more complex chains by combining     multiple chains together, or by\n",
        "\n",
        "\n",
        "combining chains with other components.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2f55d21",
      "metadata": {
        "id": "b2f55d21"
      },
      "source": [
        "We are all set. Time to get creative!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d507aa5c",
      "metadata": {
        "id": "d507aa5c",
        "outputId": "2fd04f78-433e-4930-fead-cdc0ff0ecba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spent a total of 163 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"\\nChains let us link up multiple pieces to make one dope app. Like, we can take user input, style it up with a PromptTemplate, then pass it to an LLM. We can get even more creative by combining multiple chains or mixin' chains with other components.\""
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_tokens(sequential_chain, {'text': input_text, 'style': 'a 90s rapper'})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60b52e19",
      "metadata": {
        "id": "60b52e19"
      },
      "source": [
        "## A note on langchain-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02f649da",
      "metadata": {
        "id": "02f649da"
      },
      "source": [
        "`langchain-hub` is a sister library to `langchain`, where all the chains, agents and prompts are serialized for us to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "411500c2",
      "metadata": {
        "id": "411500c2"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import load_chain"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b375e5b7",
      "metadata": {
        "id": "b375e5b7"
      },
      "source": [
        "Loading from langchain hub is as easy as finding the chain you want to load in the repository and then using `load_chain` with the corresponding path. We also have `load_prompt` and `initialize_agent`, but more on that later. Let's see how we can do this with our `LLMMathChain` we saw earlier:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbe8748d",
      "metadata": {
        "id": "fbe8748d"
      },
      "outputs": [],
      "source": [
        "llm_math_chain = load_chain('lc://chains/llm-math/chain.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebcfe67c",
      "metadata": {
        "id": "ebcfe67c"
      },
      "source": [
        "What if we want to change some of the configuration parameters? We can simply override it after loading:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d54233",
      "metadata": {
        "id": "d0d54233",
        "outputId": "92eba1cf-e47b-4df1-cc51-caee5a6a720b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_math_chain.verbose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074f8806",
      "metadata": {
        "id": "074f8806"
      },
      "outputs": [],
      "source": [
        "llm_math_chain.verbose = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "465a6cbf",
      "metadata": {
        "id": "465a6cbf",
        "outputId": "0207bf08-0db0-4d85-e3b9-ac7922f344c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_math_chain.verbose"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2cc688ca",
      "metadata": {
        "id": "2cc688ca"
      },
      "source": [
        "That's it for this example on chains.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vaFoIOMawUoL"
      },
      "id": "vaFoIOMawUoL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nd0Hoxh7wUrA"
      },
      "id": "Nd0Hoxh7wUrA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oub9vB4ewUsj"
      },
      "id": "oub9vB4ewUsj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m057FG0JwUup"
      },
      "id": "m057FG0JwUup",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dHhm9TecwUx-"
      },
      "id": "dHhm9TecwUx-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "b8e7999f96e1b425e2d542f21b571f5a4be3e97158b0b46ea1b2500df63956ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}