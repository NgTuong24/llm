{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "AD5yk3Z69FY-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aveaGbm9V1hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install"
      ],
      "metadata": {
        "id": "QNqr6qFpV2dJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LLJBkvLo1mQR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "095eb9ab-018a-402e-8522-8fb5e15dcf9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.6 (from langchain-community)\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.3.0,>=0.2.10 (from langchain-community)\n",
            "  Downloading langchain_core-0.2.11-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.4/337.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain-community)\n",
            "  Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.6->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.6->langchain-community) (2.7.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.10->langchain-community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain-community) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-community)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain-community)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.6->langchain-community) (2.18.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-community-0.2.6 langchain-core-0.2.11 langchain-text-splitters-0.2.2 langsmith-0.1.83 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.6 typing-inspect-0.9.0\n",
            "Collecting duckduckgo-search\n",
            "  Downloading duckduckgo_search-6.1.7-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (8.1.7)\n",
            "Collecting pyreqwest-impersonate>=0.4.8 (from duckduckgo-search)\n",
            "  Downloading pyreqwest_impersonate-0.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.5 in /usr/local/lib/python3.10/dist-packages (from duckduckgo-search) (3.10.6)\n",
            "Installing collected packages: pyreqwest-impersonate, duckduckgo-search\n",
            "Successfully installed duckduckgo-search-6.1.7 pyreqwest-impersonate-0.4.8\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.11)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (3.0.0)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-1.0.7-py3-none-any.whl (36 kB)\n",
            "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain_google_genai)\n",
            "  Downloading google_generativeai-0.7.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.9/163.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2.9 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.2.11)\n",
            "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.3/718.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.16.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.24.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (0.1.83)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.9->langchain_google_genai) (8.4.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.18.4)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.63.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.64.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.9->langchain_google_genai) (2024.6.2)\n",
            "Installing collected packages: google-ai-generativelanguage, google-generativeai, langchain_google_genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.4\n",
            "    Uninstalling google-ai-generativelanguage-0.6.4:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.4\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.5.4\n",
            "    Uninstalling google-generativeai-0.5.4:\n",
            "      Successfully uninstalled google-generativeai-0.5.4\n",
            "Successfully installed google-ai-generativelanguage-0.6.6 google-generativeai-0.7.1 langchain_google_genai-1.0.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "2ca0a402a70c4648a302bffea60772a7"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain-community\n",
        "!pip install -U duckduckgo-search\n",
        "!pip install langchain\n",
        "!pip install langchain_google_genai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install \"unstructured[pdf]\"\n",
        "!pip install chromadb\n",
        "!pip install -q --upgrade gdown\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "LNP6Yo8p21Ll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56cb53e4-1e08-42c8-ca5f-2a3f9bf38460"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Using cached chromadb-0.5.3-py3-none-any.whl (559 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.7.4)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
            "  Using cached chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Using cached fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "Collecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Using cached uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m764.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.18.1)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.4)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.1.3-cp39-abi3-manylinux_2_28_x86_64.whl (283 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.3)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.4.2)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.6)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (3.1.4)\n",
            "Requirement already satisfied: python-multipart>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.0.9)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
            "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=aa8ef60918cc67d82d90bfa30a822d80dd6d0070756c261e54d1cee1f1fdb186\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, ujson, python-dotenv, overrides, opentelemetry-util-http, opentelemetry-proto, importlib-metadata, httptools, dnspython, chroma-hnswlib, bcrypt, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, email_validator, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.0.0\n",
            "    Uninstalling importlib_metadata-8.0.0:\n",
            "      Successfully uninstalled importlib_metadata-8.0.0\n",
            "Successfully installed asgiref-3.8.1 bcrypt-4.1.3 chroma-hnswlib-0.7.3 chromadb-0.5.3 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.0 fastapi-cli-0.0.4 httptools-0.6.1 importlib-metadata-7.1.0 kubernetes-30.1.0 mmh3-4.1.0 monotonic-1.6 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 overrides-7.7.0 posthog-3.5.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.37.2 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-12.0\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "path_drive_pdf = 'https://drive.google.com/file/d/1CO9k4u6XFS1TD1GjTKqqnCmheRgwwYBg/view?usp=sharing'\n",
        "\n",
        "url = 'https://drive.google.com/uc?export=download&id=1CO9k4u6XFS1TD1GjTKqqnCmheRgwwYBg'\n",
        "\n",
        "# Output file name\n",
        "output = 'file.pdf'\n",
        "\n",
        "# Download the file\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "9O2KdhM-2GWN",
        "outputId": "a1002750-70ae-4035-efc5-0d7f8cb1450f"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1CO9k4u6XFS1TD1GjTKqqnCmheRgwwYBg\n",
            "To: /content/file.pdf\n",
            "100%|██████████| 347k/347k [00:00<00:00, 48.0MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.generativeai as genai\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyAk2SGsbPm5H-6K-rNgnIhQsBYwkm2GHhE'\n",
        "genai.configure(api_key='AIzaSyAk2SGsbPm5H-6K-rNgnIhQsBYwkm2GHhE')"
      ],
      "metadata": {
        "id": "5r0ZgJ8s1q1c"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z24ASnQn3Jse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GU9meg0o6OUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# data"
      ],
      "metadata": {
        "id": "LdGJkQxx6UHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.schema.document import Document\n",
        "from langchain.vectorstores.chroma import Chroma\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter"
      ],
      "metadata": {
        "id": "tntJ0kPj3Jum"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = r\"/content/file2.pdf\"\n",
        "\n",
        "CHROMA_PATH = \"./Chroma_finance5\""
      ],
      "metadata": {
        "id": "LJDLKNAc3Jwe"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents():\n",
        "    # from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
        "    # document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
        "    # return document_loader.load()\n",
        "\n",
        "    from langchain_community.document_loaders import PyPDFLoader\n",
        "    loader = PyPDFLoader(DATA_PATH)\n",
        "    pages = loader.load_and_split()\n",
        "    return pages\n",
        "\n",
        "    # from langchain_community.document_loaders import UnstructuredFileLoader\n",
        "    # loader = UnstructuredFileLoader(DATA_PATH)\n",
        "    # docs = loader.load()\n",
        "    # return docs\n",
        "\n",
        "def split_documents(documents: list[Document]):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=800,\n",
        "        chunk_overlap=80,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "    return text_splitter.split_documents(documents)\n",
        "\n",
        "\n",
        "def get_embedding_function():\n",
        "    gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "    return gemini_embeddings\n",
        "\n",
        "\n",
        "def add_to_chroma(chunks: list[Document]):\n",
        "    db = Chroma(\n",
        "        persist_directory=CHROMA_PATH, embedding_function=get_embedding_function()\n",
        "    )\n",
        "\n",
        "    # Calculate Page IDs.\n",
        "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
        "\n",
        "    # Add or Update the documents.\n",
        "    existing_items = db.get(include=[])  # IDs are always included by default\n",
        "    existing_ids = set(existing_items[\"ids\"])\n",
        "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
        "\n",
        "    new_chunks = []\n",
        "    for chunk in chunks_with_ids:\n",
        "        if chunk.metadata[\"id\"] not in existing_ids:\n",
        "            new_chunks.append(chunk)\n",
        "\n",
        "    if len(new_chunks):\n",
        "        print(f\"đŸ‘‰ Adding new documents: {len(new_chunks)}\")\n",
        "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
        "        # print(new_chunk_ids)\n",
        "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
        "        db.persist()\n",
        "    else:\n",
        "        print(\"âœ… No new documents to add\")\n",
        "\n",
        "\n",
        "def calculate_chunk_ids(chunks):\n",
        "    last_page_id = None\n",
        "    current_chunk_index = 0\n",
        "\n",
        "    for chunk in chunks:\n",
        "        # print(chunk)\n",
        "        source = chunk.metadata.get(\"source\")\n",
        "        page = chunk.metadata.get(\"page\")\n",
        "        # print(page)\n",
        "        current_page_id = f\"{source}:{page}\"\n",
        "        if current_page_id == last_page_id:\n",
        "            current_chunk_index += 1\n",
        "        else:\n",
        "            current_chunk_index = 0\n",
        "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
        "        last_page_id = current_page_id\n",
        "        # print(chunk_id)\n",
        "        chunk.metadata[\"id\"] = chunk_id\n",
        "\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "v7qmtElQ3Jyu"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_docs():\n",
        "#     loader = WebBaseLoader(\n",
        "#         \"https://www.meetjamie.ai/blog/summary-of-best-100-gpt-4-prompts\",\n",
        "#     )\n",
        "#     # docs = loader.load()\n",
        "#     # text_splitter = RecursiveCharacterTextSplitter(\n",
        "#     #     chunk_size=200,\n",
        "#     #     chunk_overlap=20\n",
        "#     # )\n",
        "#     # splitDocs = text_splitter.split_documents(docs)\n",
        "#     docs = \"\"\"\n",
        "#     \"\"\"\n",
        "\n",
        "#     text_splitter = CharacterTextSplitter(\n",
        "#         separator=\"\\n\",\n",
        "#         chunk_size=200,\n",
        "#         chunk_overlap=100,\n",
        "#         length_function=len,\n",
        "#         is_separator_regex=False,\n",
        "#     )\n",
        "#     splitDocs = text_splitter.create_documents([docs])\n",
        "#     return splitDocs"
      ],
      "metadata": {
        "id": "F-j0hDdH3J0-"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = load_documents()\n",
        "# print(\"documents\", documents)\n",
        "chunks = split_documents(documents)\n",
        "add_to_chroma(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWQLpuc13J4h",
        "outputId": "93bb36ce-5e96-48ef-df21-b2d25ee69b48"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of existing documents in DB: 115\n",
            "âœ… No new documents to add\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "mB4Iw8C36Xau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from operator import itemgetter\n",
        "from langchain_core.runnables import (\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from typing import List\n",
        "from operator import itemgetter\n",
        "from langchain_community.utilities import DuckDuckGoSearchAPIWrapper\n",
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "6eyq-5eQ1q3d"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "model = GoogleGenerativeAI(model=\"models/gemini-1.5-pro-001\", temperature=0.1)\n",
        "embeddings = get_embedding_function()\n",
        "db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings)\n",
        "retrieval = db.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# wrapper = DuckDuckGoSearchAPIWrapper(region=\"jp-jp\", time=\"d\", max_results=1) # us-en  # jp-jp\n",
        "wrapper = DuckDuckGoSearchAPIWrapper(region=\"jp-jp\", time=\"y\", max_results=1) # us-en  # jp-jp\n",
        "search = DuckDuckGoSearchResults(api_wrapper=wrapper, source=\"news\", max_results=1)"
      ],
      "metadata": {
        "id": "7YK3wKCn1q5l"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yl8bIr281q72"
      },
      "execution_count": 338,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# format_output"
      ],
      "metadata": {
        "id": "WUWYhCiQ6mxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs_to_document(docs: str):\n",
        "    # print(\"format_docs_to_document\")\n",
        "    key = ['snippet:', 'title:', 'link:']\n",
        "    docs = docs[1:-1]\n",
        "    list_ = docs.split(\"],\")\n",
        "    links = []\n",
        "    documents = \"\"\n",
        "    for doc in list_:\n",
        "        ind_1 = doc.find(key[0])\n",
        "        ind_2 = doc.find(key[1])\n",
        "        ind_3 = doc.find(key[2])\n",
        "        documents += doc[ind_1: ind_2]\n",
        "    # print(documents)\n",
        "    return documents"
      ],
      "metadata": {
        "id": "Dk0LN_YG1q-F"
      },
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_output_name_entity(result_entity):\n",
        "  list_entity = []\n",
        "  if ('{' and '}') in result_entity:\n",
        "    import json\n",
        "    json_object = json.loads(result_entity[result_entity.find('{'):result_entity.find('}')+1])\n",
        "    # print(json_object)\n",
        "\n",
        "    if len(json_object):\n",
        "      # print(list(json_object.keys()))\n",
        "      # print(\"---------\")\n",
        "      key = list(json_object.keys())[0]\n",
        "      for ind, obj in enumerate(json_object[key]):\n",
        "        list_entity.append(obj)\n",
        "        if ind == 5:\n",
        "          break\n",
        "    # list_to_str = \"\\n\\n\".join(list_entity)\n",
        "  return list_entity"
      ],
      "metadata": {
        "id": "Vje9zAUALyxq"
      },
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs_to_links(docs: str):\n",
        "    # print(\"docs to link:\")\n",
        "    # print(docs)\n",
        "    key = ['snippet:', 'title:', 'link:']\n",
        "    docs = docs[1:-1]\n",
        "    list_ = docs.split(\"],\")\n",
        "    list_ = [list_[0]]\n",
        "    links = []\n",
        "    for doc in list_:\n",
        "      ind_2 = doc.find(key[1])\n",
        "      ind_3 = doc.find(key[2])\n",
        "      # print(doc[ind_3+6:])\n",
        "      links.append(doc[ind_2 + 7:ind_3])\n",
        "      links.append(doc[ind_3+6:])\n",
        "    return links"
      ],
      "metadata": {
        "id": "4N979Zpx1rAe"
      },
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_sources(docs: str):\n",
        "    key = ['snippet:', 'title:', 'link:']\n",
        "    docs = docs[1:-1]\n",
        "    list_doc = docs.split(\"],\")\n",
        "    source = []\n",
        "    for doc in list_doc:\n",
        "        metadata = {}\n",
        "        ind_1 = doc.find(key[0])\n",
        "        ind_2 = doc.find(key[1])\n",
        "        ind_3 = doc.find(key[2])\n",
        "        metadata['title'] = doc[ind_2 + 7:ind_3]\n",
        "        metadata['source'] = doc[ind_3 + 6:]\n",
        "        document = Document(\n",
        "            page_content = doc[ind_1+2 + 7:ind_2],\n",
        "            metadata=metadata\n",
        "        )\n",
        "        source.append(document)\n",
        "    return source"
      ],
      "metadata": {
        "id": "VAsxZX6P1r5M"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs: List[Document]) -> str:\n",
        "    \"\"\"Convert Documents to a single string.:\"\"\"\n",
        "    formatted = [\n",
        "        f\"Article Snippet: {doc.page_content}\" for doc in docs\n",
        "    ]\n",
        "    return \"\\n\\n\" + \"\\n\\n\".join(formatted)"
      ],
      "metadata": {
        "id": "nYVOol2u1r7e"
      },
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GKoOslFO6vy9"
      },
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prompt"
      ],
      "metadata": {
        "id": "ZzIv0AZt67sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the following question based on this context:\n",
        "{context}\n",
        "Question: {question}\n",
        "Note: Please answer in Japanese.\n",
        "\"\"\"\n",
        "template_japan = \"\"\"\n",
        "このコンテキストに基づいて次の質問に答えてください:\n",
        "{context}\n",
        "質問: {question}\n",
        "注: 日本語で回答してください。\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Gn4D5DED8P4W"
      },
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template2 = \"\"\"You are the AI ​​language model assistant, extracting name entities, main header from text.\n",
        "This is the context: {context}\n",
        "Please extract name entity , header.\n",
        "Json architecture contains only one key.\n",
        "Formart Json only:\n",
        "  \"name\": [name1/header1, name2/header2];\n",
        "Rearrange headings to the most general level, limiting the number to less than 10\n",
        "\"\"\"\n",
        "template2_japan = \"\"\"\n",
        "あなたは AI 言語モデル アシスタントで、テキストから名前エンティティ、メイン ヘッダーを抽出しています。\n",
        "これはコンテキストです: {context}\n",
        "名前エンティティ、ヘッダーを抽出してください。\n",
        "Json アーキテクチャにはキーが 1 つだけ含まれています。\n",
        "Json のみの形式:\n",
        "  \"name\": [name1/header1, name2/header2];\n",
        "注記：\n",
        "1. 見出しを最も一般的なレベルに並べ替え、数を 10 未満に制限します\n",
        "2. 日本語で回答する必要があります。\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Lb3aufMh6v2g"
      },
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template3 = \"\"\"\n",
        "You are a helpful AI assistant. Provide the name of entity and some snippets of articles DuckDuckGoSearch for\n",
        "generate feedback. Please complete the answer yourself.\n",
        "This is the name of the entity: {context}\n",
        "Definition of {context}, summury and feetback answer\n",
        "If none of the articles answer the question, just say you don't know.\"\n",
        "\"\"\"\n",
        "# template3_japan = \"\"\"あなたは役に立つ AI アシスタントです。\n",
        "# あなたは役に立つ AI アシスタントです。エンティティの名前と、DuckDuckGoSearch で検索した記事の抜粋を入力してください。\n",
        "# フィードバックを生成してください。回答は自分で記入してください。\n",
        "# これはエンティティの名前です: {context}\n",
        "# 質問を自動的に生成します。{context} の定義は?\n",
        "# 記事のどれも質問に答えていない場合は、わからないとだけ言ってください。\"\n",
        "# 注記：\n",
        "# 1. 私が要求した情報を除き、返された結果に質問や要求を繰り返さないでください。\n",
        "# \"\"\"\n",
        "\n",
        "template3_japan = \"\"\"\n",
        "あなたは役に立つ AI アシスタントです。エンティティの名前と、DuckDuckGoSearch で検索した記事の抜粋を入力します。\n",
        "フィードバックを生成します。あなた自身の答えを書いてください。\n",
        "これはエンティティの名前です: {context}\n",
        "{context}の定義\n",
        "注記：\n",
        "1. 日本語で回答する必要があります。\n",
        "2. 質問を繰り返したり、要求した以上の情報を求めたりしないでください。\n",
        "3. 質問に回答する記事がない場合、または回答がない場合は結果が表示されません\n",
        "\"\"\"\n",
        "\n",
        "# template3_japan = \"\"\"\n",
        "# あなたは役に立つ AI アシスタントです。タイトル、ヘッダー、DuckDuckGoSearch で検索したドキュメントを入力します。\n",
        "# フィードバックを生成します。あなた自身の答えを書いてください。\n",
        "# これはエンティティの名前です: {context}\n",
        "# {コンテキスト}の定義\n",
        "# 注記：\n",
        "# 1. 日本語で答えてください。\n",
        "# 2. 質問を繰り返したり、要求以上の情報を求めたりしないでください。\n",
        "# 3. 質問に回答する記事がない場合、または回答がない場合は結果は表示されません。\n",
        "# \"\"\""
      ],
      "metadata": {
        "id": "qqhY0OOS6v52"
      },
      "execution_count": 401,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# chain"
      ],
      "metadata": {
        "id": "A-Ty_k5W8cZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = PromptTemplate.from_template(template_japan)\n",
        "\n",
        "def format_output_chain_1(result):\n",
        "  #[{'id': '/content/file.pdf:None:39', 'source': '/content/file.pdf'}, {'id': '/content/file.pdf:None:0', 'source': '/content/file.pdf'}, {'id': '/content/file.pdf:None:8', 'source': '/content/file.pdf'}]\n",
        "  answer = result['result']\n",
        "  context = result['source_documents']\n",
        "  context_str = \"\"\n",
        "  for doc in context:\n",
        "    metadata = doc.metadata  # {'id': '/content/file.pdf:None:39', 'source': '/content/file.pdf'}\n",
        "    for key, value in metadata.items():\n",
        "        context_str += f\"{key}: {value}, \"\n",
        "    context_str += \",\\n \"\n",
        "  return {'answer': answer, 'context': context_str}\n",
        "\n",
        "chain_type_kwargs = {\"prompt\": prompt_1}\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=model,\n",
        "                                  chain_type=\"stuff\",\n",
        "                                  retriever=retrieval,\n",
        "                                  return_source_documents=True,\n",
        "                                  chain_type_kwargs=chain_type_kwargs)\n",
        "chain = (\n",
        "    qa_chain\n",
        "    | format_output_chain_1\n",
        ")\n",
        "# res = chain.invoke(\"The overall state of Vietnam's financial sector?\")\n"
      ],
      "metadata": {
        "id": "BviiysYw8b1G"
      },
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class Output(BaseModel):\n",
        "#     name: str = Field(description=\"The name or header of the entity is extracted in context\")\n",
        "\n",
        "class Output(BaseModel):\n",
        "    name: str = Field(description=\"エンティティの名前またはヘッダーはコンテキスト内で抽出されます\")\n",
        "parser = JsonOutputParser(pydantic_object=Output)\n",
        "\n",
        "prompt_2 = PromptTemplate(\n",
        "    template=template2_japan,\n",
        "    input_variables=[\"context\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "chain2 = (\n",
        "    prompt_2\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        "    | format_output_name_entity\n",
        ")\n",
        "# chain2.invoke({\"context\": res['answer']})"
      ],
      "metadata": {
        "id": "Oap4mOKm8b3O"
      },
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_3 = PromptTemplate.from_template(template3_japan)\n",
        "\n",
        "answer = prompt_3 | model | StrOutputParser()\n",
        "\n",
        "format_out_docs = itemgetter(\"docs\") | RunnableLambda(format_docs_to_document)\n",
        "format_out = itemgetter(\"docs\") | RunnableLambda(format_docs_to_links)\n",
        "chain_search = (\n",
        "    RunnableParallel(question=RunnablePassthrough(), docs=search)\n",
        "        .assign(context=format_out_docs)      # truyá»n output key vao assign\n",
        "        .assign(answer=answer)\n",
        "        .assign(context=format_out)\n",
        "        #.pick([\"answer\", \"context\"])        # show output key\n",
        "\n",
        ")\n",
        "# list_entity = []  # output chain 2\n",
        "# result_search = []\n",
        "# for name in list_entity:\n",
        "#   result_search.append(chain_search.invoke(name))"
      ],
      "metadata": {
        "id": "5fFZyQ4j8b5u"
      },
      "execution_count": 374,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workflow"
      ],
      "metadata": {
        "id": "AD5yk3Z69FY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results(ques):\n",
        "  # res1 = chain.invoke(ques)\n",
        "  # print(res1['answer'])\n",
        "  list_entity = chain2.invoke({\"context\": ques})\n",
        "  print(\"name_entity: \", list_entity)\n",
        "\n",
        "  result = []\n",
        "  if len(list_entity) != 0:\n",
        "    for entity in list_entity:\n",
        "      res = chain_search.invoke(entity)\n",
        "      result.append(res)\n",
        "  final_result = \"\"\n",
        "  # final_result += res1['answer'] + \"\\n\" + \"SOURCE: \\n\" + res1['context']+ '\\n'\n",
        "  for val in result:\n",
        "    final_result += val['answer'] + \"\\n\" + \"SOURCE: \\n\" + \"\\n\".join(val['context']) + '\\n\\n'\n",
        "    # final_result += \"SOURCE: \\n\" + \"\\n\".join(val['context']) + '\\n\\n'\n",
        "  return final_result"
      ],
      "metadata": {
        "id": "50pPXtMI9VAW"
      },
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# doc = \"\"\"\n",
        "# | 項目 | 2022年度 | 2023年度 | 2025年3月期予測 | 2026年3月期予測 | 2027年3月期予測 | 2028年3月期予測 | 2029年3月期予測 |\n",
        "# |---|---|---|---|---|---|---|---|\n",
        "# | **営業活動によるキャッシュフロー** | 101,610,807 | 127,081,966 | 177,914,752 | 237,219,165 | 316,292,219 | 421,722,959 | 562,297,279 |\n",
        "# |   | 税引前当期純利益 | 36,464,000 | 52,091,000 | 72,927,400 | 97,236,715 | 129,648,953 | 172,865,271 | 230,486,628 |\n",
        "# |   | 減価償却費 |  |  |  |  |  |  |  |\n",
        "# |   | その他 | 65,146,807 | 74,990,966 | 104,987,352 | 139,982,450 | 186,643,266 | 248,857,688 | 331,810,651 |\n",
        "# | **投資活動によるキャッシュフロー** | 118,024 | -5,478,410 | -7,669,774 | -10,226,366 | -13,635,154 | -18,180,206 | -24,240,274 |\n",
        "# |   | 有形固定資産の取得による支出 |  |  |  |  |  |  |  |\n",
        "# |   | 無形固定資産の取得による支出 |  |  |  |  |  |  |  |\n",
        "# |   | 投資有価証券の取得による支出 |  |  |  |  |  |  |  |\n",
        "# |   | その他 | 118,024 | -5,478,410 | -7,669,774 | -10,226,366 | -13,635,154 | -18,180,206 | -24,240,274 |\n",
        "# | **財務活動によるキャッシュフロー** | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
        "# |   | 短期借入金の純増減額 |  |  |  |  |  |  |  |\n",
        "# |   | 長期借入金の純増減額 |  |  |  |  |  |  |  |\n",
        "# |   | その他 |  |  |  |  |  |  |  |\n",
        "# | **現金及び現金同等物に係る換算差額** |  |  |  |  |  |  |  |\n",
        "# | **現金及び現金同等物に係る増減額** | 67,641,866 | 121,603,556 | 170,244,978 | 226,992,799 | 302,657,065 | 403,542,753 | 538,057,005 |\n",
        "# | **現金及び現金同等物の期首残高** | 104,491,954 | 172,133,820 | 342,378,798 | 569,371,597 | 872,028,662 | 1,275,571,415 | 1,679,114,168 |\n",
        "# | **現金及び現金同等物の期末残高** | 172,133,820 | 293,737,376 | 512,623,776 | 796,364,396 | 1,174,685,727 | 1,679,114,168 | 2,217,171,173 |\n",
        "# \"\"\"\n",
        "# name = chain2.invoke({\"context\": doc})"
      ],
      "metadata": {
        "id": "G9zO-auUWSc2"
      },
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = \"\"\"\n",
        "経営分析・事業計画 [ 収益予測 ]\n",
        "2022年3月期実績\t2023年3月期実績\t2024年3月期予測\t2025年3月期予測\t2026年3月期予測\t2027年3月期予測\t2028年3月期予測\n",
        "損益計算書\n",
        "売上高\t462,804\t766,200\t842,820\t927,133\t1,020,159\t1,123,387\t1,238,288\n",
        "売上原価\t3,086\t6,086\t6,590\t7,133\t7,719\t8,352\t9,036\n",
        "売上総利益\t459,718\t760,113\t836,230\t919,999\t1,012,440\t1,115,034\t1,229,252\n",
        "販売費及び一般管理費\t264,677\t343,196\t389,575\t441,661\t499,828\t564,602\t636,562\n",
        "営業利益\t195,040\t416,917\t446,655\t478,338\t512,612\t550,432\t592,690\n",
        "営業外収益\t26\t26\t28\t30\t32\t34\t36\n",
        "営業外費用\t583\t583\t631\t683\t739\t800\t865\n",
        "経常利益\t194,484\t416,361\t446,052\t478,085\t512,205\t549,976\t592,281\n",
        "特別利益\t0\t0\t0\t0\t0\t0\t0\n",
        "特別損失\t3,636\t0\t0\t0\t0\t0\t0\n",
        "税金等調整前当期純利益\t190,847\t416,361\t446,052\t478,085\t512,205\t549,976\t592,281\n",
        "法人税等合計\t57,254\t124,908\t133,816\t143,426\t153,662\t164,593\t176,284\n",
        "当期純利益\t133,593\t291,453\t312,236\t334,659\t358,543\t385,383\t416,007\n",
        "貸借対照表\n",
        "資産合計\t695,027\t992,895\t1,126,492\t1,277,880\t1,448,813\t1,641,260\t1,857,414\n",
        "流動資産\t651,579\t930,827\t1,064,424\t1,215,708\t1,386,546\t1,578,897\t1,794,751\n",
        "現金及び預金\t113,707\t162,439\t296,055\t443,710\t612,699\t806,868\t1,029,286\n",
        "売上債権\t80,126\t114,465\t126,912\t140,593\t155,632\t172,165\t190,382\n",
        "その他流動資産\t457,746\t653,923\t641,457\t631,405\t618,215\t600,864\t594,083\n",
        "固定資産\t43,448\t62,068\t62,068\t62,068\t62,068\t62,068\t62,068\n",
        "投資その他の資産\t43,448\t62,068\t62,068\t62,068\t62,068\t62,068\t62,068\n",
        "繰延資産\t0\t0\t0\t0\t0\t0\t0\n",
        "負債合計\t21,571\t30,816\t33,898\t37,288\t41,017\t45,119\t49,630\n",
        "流動負債\t61,823\t88,321\t97,153\t106,870\t117,557\t129,313\t142,244\n",
        "その他流動負債\t61,823\t88,321\t97,153\t106,870\t117,557\t129,313\t142,244\n",
        "固定負債\t21,509\t30,728\t33,801\t37,188\t40,907\t44,997\t49,483\n",
        "長期借入金\t21,509\t30,728\t33,801\t37,188\t40,907\t44,997\t49,483\n",
        "純資産合計\t673,456\t962,079\t1,092,594\t1,240,592\t1,407,796\t1,596,141\t1,807,784\n",
        "株主資本\t118,647\t169,496\t381,732\t616,401\t885,955\t1,192,838\t1,540,345\n",
        "資本金\t70,000\t100,000\t100,000\t100,000\t100,000\t100,000\t100,000\n",
        "利益剰余金\t48,647\t69,496\t281,732\t516,401\t785,955\t1,092,838\t1,440,345\n",
        "その他包括利益累計額\t1\t0\t0\t0\t0\t0\t0\n",
        "新株予約権\t1\t0\t0\t0\t0\t0\t0\n",
        "予測の根拠\n",
        "\n",
        "売上高:\n",
        "\n",
        "2024年3月期: サステナビリティ・ESG経営への関心の高まりを背景に、顧客企業数は前年比15%増の成長を見込む。それに伴い、売上高も15%増加すると予測。\n",
        "2025年3月期: 顧客企業数の増加は13%と予測。加えて、既存顧客へのクロスセル、アップセル施策が奏功し、顧客一人当たりの売上も増加するため、売上高は10%増加すると予測。\n",
        "2026年3月期: 顧客企業数の増加は8%と予測。既存顧客へのサービス浸透により、売上高は9%増加すると予測。\n",
        "2027年3月期: 顧客企業数の増加は7%と予測。サービスの安定的な利用と、新規サービスの導入により、売上高は8%増加すると予測。\n",
        "2028年3月期: 顧客企業数の増加は7%と予測。市場の成熟に伴い、売上高の成長は鈍化傾向となるが、7%の増加を見込む。\n",
        "売上原価:\n",
        "\n",
        "売上高の増加に伴い、比例的に増加すると予測。\n",
        "販売費及び一般管理費:\n",
        "\n",
        "2024年3月期: 営業体制強化のための人材採用、広告宣伝費の増加により、売上高に対して増加傾向となる。売上高比で6ポイント増加すると予測。\n",
        "2025年3月期: 引き続き、人材採用、広告宣伝費への投資は継続するものの、売上高の増加に伴い、売上高比は2ポイント増加に抑えられると予測。\n",
        "2026年3月期: 売上高の増加に伴い、売上高比は横ばいとなると予測。\n",
        "2027年3月期: 業務効率化、コスト削減施策により、売上高比は減少に転じると予測。\n",
        "2028年3月期: 引き続き、業務効率化、コスト削減施策を推進し、売上高比は減少傾向を維持すると予測。\n",
        "営業外収益:\n",
        "\n",
        "預金利息による収益増加を見込む。\n",
        "営業外費用:\n",
        "\n",
        "為替変動による影響を除き、ほぼ横ばいとなると予測。\n",
        "特別利益・特別損失:\n",
        "\n",
        "特に大きな要因がないため、計上しない。\n",
        "法人税等合計:\n",
        "\n",
        "税金等調整前当期純利益の30.62%を計上。\n",
        "留意点:\n",
        "\n",
        "上記の予測は、現時点で入手可能な情報に基づくものであり、実際の業績は、今後の経済状況、市場動向、競争環境等の変化により、大きく異なる可能性があります。\n",
        "特に、競合他社の動向、法規制の変更、社会情勢の変化などが、業績に大きな影響を与える可能性があります。\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ocwNzVyUgGAq"
      },
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_results(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgX9IU3lWSe2",
        "outputId": "8ca423aa-a8db-48bb-89d3-df762ddc8670"
      },
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name_entity:  ['損益計算書', '売上高', '売上原価', '売上総利益', '販売費及び一般管理費', '営業利益']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eA7h-3dKkiA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rspRAMcWSiZ",
        "outputId": "b06777f0-f72d-483d-e657-e1612901e3cb"
      },
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "与えられたテキストスニペットは、「損益計算書」と「営業利益」について言及しており、特に営業利益がマイナスの場合のデメリットや、損益計算書の具体的な内容（売上高、売上原価、販売費及び一般管理費など）について触れています。また、損益計算書における誤りや、税金に関する記述も見られます。\n",
            "\n",
            "これらのことから、エンティティの名前は「**損益計算書**」または「**P/L（Profit and Loss Statement）**」であると考えられます。 \n",
            "\n",
            "SOURCE: \n",
            "損益計算書において、営業利益がマイナスになると、どういったデメリットが生じるの... - Yahoo!知恵袋, \n",
            "https://detail.chiebukuro.yahoo.co.jp/qa/question_detail/q14300535219\n",
            "\n",
            "これらの抜粋は、「売上高」というエンティティについて言及しているようです。 \n",
            "\n",
            "これらの抜粋は、小売売上高の増加率の低下、企業の売上高と利益の伸びを評価することの重要性、特定の企業の売上高の増加、そして企業の月次売上高の概要を提供しています。 \n",
            "\n",
            "SOURCE: \n",
            "豪小売売上高が予想以上の伸び、中銀による利上げの根拠強まる, \n",
            "https://www.bloomberg.co.jp/news/articles/2024-07-03/SG0YDLT0AFB400\n",
            "\n",
            "エンティティの名前: **売上原価**\n",
            "\n",
            "提供されたスニペットは、売上原価の定義、計算方法、計上方法、そして売上原価に影響を与える要因（円安やクラウドサービスの仕入高など）について言及しています。 \n",
            "\n",
            "したがって、これらのスニペットは「売上原価」というエンティティに関連しており、その様々な側面を説明しています。 \n",
            "\n",
            "SOURCE: \n",
            "rakumo：個人投資家向けオンライン説明会文字起こしVol.1 | マネーポストWEB, \n",
            "https://www.moneypost.jp/1163057\n",
            "\n",
            "これらのスニペットに基づいて、エンティティ名は会社名である可能性が高いです。 \n",
            "\n",
            "根拠：\n",
            "\n",
            "* すべてのスニペットは、「売上総利益率」、「売上高ガイダンス」、「純利益」など、企業の財務実績に関連する情報を示しています。\n",
            "* 特に最初のスニペットでは、「アビッドバイオサービス」という会社名が明示されており、売上高ガイダンスを発表しています。\n",
            "\n",
            "したがって、これらのスニペットは、異なる会社の財務実績に関する断片的な情報である可能性があります。 \n",
            "\n",
            "SOURCE: \n",
            "決算説明会：アビッドバイオサービシズ、第4四半期の売上高は過去最高、2025年度の見通しは楽観的, \n",
            "https://jp.investing.com/news/stock-market-news/article-93CH-798754\n",
            "\n",
            "申し訳ありませんが、提供された情報からエンティティの名前と定義を判断することはできません。 \n",
            "\n",
            "二つのスニペットは全く同じ文章であり、「世ノ果テデ人形ハ…」というイベントまたは作品に関する注意書きの一部である可能性があります。 \n",
            "\n",
            "エンティティの名前と定義を明確にするためには、より多くのコンテキストが必要です。例えば、これらのスニペットがどこで見つかったのか、どのようなウェブサイトからの抜粋なのかを教えていただけると幸いです。 \n",
            "\n",
            "SOURCE: \n",
            "琴葉らいむ生誕祭『〜A Lime Tea Party〜』世ノ果テデ人形ハ唯哂フ。 のチケット購入・予約は TIGET から, \n",
            "https://tiget.net/events/331239\n",
            "\n",
            "与えられたテキストスニペットから、エンティティ名は特定できません。テキストは複数の企業（アスクル、昭栄薬品＜3537＞、美樹工業）の業績に関する断片的な情報を含んでいますが、特定のエンティティ名を示すものはありません。 \n",
            "\n",
            "SOURCE: \n",
            "アスクルの営業益6%増 25年5月期、企業向け通販好調 - 日本経済新聞, \n",
            "https://www.nikkei.com/article/DGXZQOUC02BTB0S4A700C2000000/\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7cw0lV01WSlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # ques = \"The overall state of Vietnam's financial sector?\"\n",
        "# ques = \"ベトナムの金融セクターの全体的な状況\"\n",
        "# # ques = \"what is The Determinants of Financial Inclusion in Vietnam\"\n",
        "# # ques = 'ベトナムにおける金融包摂の決定要因は何ですか?'\n",
        "# # ques = \"金融包摂の決定要因は何ですか?\"\n",
        "# # ques = \"金融デジタル化がもたらす恩恵は大きい。問題は、その恩恵をどのくらい享受できるかをめぐ\"\n",
        "# # ques = \"有名なスポーツは何ですか?\"\n",
        "# # ques = \"金融デジタル化は金融包摂につながるか?\"\n",
        "# final = get_results(ques)"
      ],
      "metadata": {
        "id": "mxikDZox9VC3"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zq1_RTj9VE2",
        "outputId": "2f955732-8990-4f58-ba21-2c3ad789a860"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "申し訳ありませんが、この文章は日本の金融包摂に関するものであり、ベトナムの金融セクターの状況については言及していません。そのため、ご質問にお答えできません。 \n",
            "\n",
            "SOURCE: \n",
            "id: /content/file2.pdf:7:1, page: 7, source: /content/file2.pdf, ,\n",
            " id: /content/file2.pdf:0:0, page: 0, source: /content/file2.pdf, ,\n",
            " id: /content/file2.pdf:5:1, page: 5, source: /content/file2.pdf, ,\n",
            " \n",
            "これらの検索結果から、エンティティは **新紙幣** であると推測できます。 \n",
            "\n",
            "これらの抜粋は、20年ぶりに発行された新しい紙幣について言及しており、7月3日に日本銀行から各金融機関に引き渡され始めました。  \n",
            "\n",
            "SOURCE: \n",
            "新紙幣発行始まる 一万円札に渋沢栄一 五千円札に津田梅子 千円札に北里柴三郎 銀行には両替で多くの利用客 | Nhk | 日本銀行（日銀）, \n",
            "https://www3.nhk.or.jp/news/html/20240703/k10014499941000.html\n",
            "20年ぶりの新紙幣きょう発行 午前中に手にできる金融機関も | Nhk | 日本銀行（日銀）, \n",
            "https://www3.nhk.or.jp/news/html/20240702/k10014499011000.html\n",
            "新紙幣発行始まる 渋沢栄一らの肖像、日銀から銀行へ続々配送, \n",
            "https://www.asahi.com/articles/ASS727WG0S72ULFA007M.html\n",
            "20年ぶりの新紙幣発行 日銀神戸支店で各金融機関への引き渡し始まる／兵庫県（サンテレビ） - Yahoo!ニュース, \n",
            "https://news.yahoo.co.jp/articles/a49d4767f0e2b8b97bdd492de6a4a107635e58f0\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "s1mG81pD9bzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ques = \"The overall state of Vietnam's financial sector?\"\n",
        "# ques = \"what is The Determinants of Financial Inclusion in Vietnam\"\n",
        "# quess = \"ベトナムにおける金融包摂の決定要因は何ですか?\"\n",
        "# quess = \"ベトナムの金融セクターの全体的な状況\"\n",
        "\n",
        "\n",
        "doc = \"\"\"\n",
        "| 項目 | 2022年度 | 2023年度 | 2025年3月期予測 | 2026年3月期予測 | 2027年3月期予測 | 2028年3月期予測 | 2029年3月期予測 |\n",
        "|---|---|---|---|---|---|---|---|\n",
        "| **営業活動によるキャッシュフロー** | 101,610,807 | 127,081,966 | 177,914,752 | 237,219,165 | 316,292,219 | 421,722,959 | 562,297,279 |\n",
        "|   | 税引前当期純利益 | 36,464,000 | 52,091,000 | 72,927,400 | 97,236,715 | 129,648,953 | 172,865,271 | 230,486,628 |\n",
        "|   | 減価償却費 |  |  |  |  |  |  |  |\n",
        "|   | その他 | 65,146,807 | 74,990,966 | 104,987,352 | 139,982,450 | 186,643,266 | 248,857,688 | 331,810,651 |\n",
        "| **投資活動によるキャッシュフロー** | 118,024 | -5,478,410 | -7,669,774 | -10,226,366 | -13,635,154 | -18,180,206 | -24,240,274 |\n",
        "|   | 有形固定資産の取得による支出 |  |  |  |  |  |  |  |\n",
        "|   | 無形固定資産の取得による支出 |  |  |  |  |  |  |  |\n",
        "|   | 投資有価証券の取得による支出 |  |  |  |  |  |  |  |\n",
        "|   | その他 | 118,024 | -5,478,410 | -7,669,774 | -10,226,366 | -13,635,154 | -18,180,206 | -24,240,274 |\n",
        "| **財務活動によるキャッシュフロー** | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
        "|   | 短期借入金の純増減額 |  |  |  |  |  |  |  |\n",
        "|   | 長期借入金の純増減額 |  |  |  |  |  |  |  |\n",
        "|   | その他 |  |  |  |  |  |  |  |\n",
        "| **現金及び現金同等物に係る換算差額** |  |  |  |  |  |  |  |\n",
        "| **現金及び現金同等物に係る増減額** | 67,641,866 | 121,603,556 | 170,244,978 | 226,992,799 | 302,657,065 | 403,542,753 | 538,057,005 |\n",
        "| **現金及び現金同等物の期首残高** | 104,491,954 | 172,133,820 | 342,378,798 | 569,371,597 | 872,028,662 | 1,275,571,415 | 1,679,114,168 |\n",
        "| **現金及び現金同等物の期末残高** | 172,133,820 | 293,737,376 | 512,623,776 | 796,364,396 | 1,174,685,727 | 1,679,114,168 | 2,217,171,173 |\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "u1TANaQYOTqB"
      },
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_japan = \"\"\"\n",
        "このコンテキストに基づいて次の質問に答えてください:\n",
        "{context}\n",
        "質問: {question}\n",
        "注: 日本語で回答してください。\n",
        "\"\"\"\n",
        "# template2_japan = \"\"\"\n",
        "# あなたは AI 言語モデル アシスタントで、テキストから名前エンティティ、メイン ヘッダーを抽出しています。\n",
        "# これはコンテキストです: {output_1}\n",
        "# 名前エンティティ、ヘッダーを抽出してください。\n",
        "# Json アーキテクチャにはキーが 1 つだけ含まれています。\n",
        "# Json のみの形式:\n",
        "#   \"name\": [name1/header1, name2/header2];\n",
        "# 注記：\n",
        "# 1. 見出しを最も一般的なレベルに並べ替え、数を 10 未満に制限します\n",
        "# 2. 日本語で回答する必要があります。\n",
        "# \"\"\"\n",
        "\n",
        "template2_japan = \"\"\"\n",
        "AI言語モデルアシスタントを使用して、テキストから名前エンティティ、メインタイトルを抽出しています。\n",
        "コンテキストは次のとおりです: {output_1}\n",
        "エンティティ名、タイトルを抽出します。\n",
        "返される結果は文字列です。\n",
        "注記：\n",
        "1. タイトルを最も一般的なレベルで配置し、数を 10 未満に制限します\n",
        "2. 日本語で答えてください。\n",
        "\"\"\"\n",
        "template3_japan = \"\"\"\n",
        "あなたは役に立つ AI アシスタントです。エンティティの名前と、DuckDuckGoSearch で検索した記事の抜粋を入力します。\n",
        "フィードバックを生成します。あなた自身の答えを書いてください。\n",
        "これはエンティティの名前です: {output_2}\n",
        "{output_2}の定義\n",
        "注記：\n",
        "1. 日本語で回答する必要があります。\n",
        "2. 質問を繰り返したり、要求した以上の情報を求めたりしないでください。\n",
        "3. 質問に回答する記事がない場合、または回答がない場合は結果が表示されません\n",
        "\"\"\"\n",
        "\n",
        "template3_japan = \"\"\"\n",
        "あなたは役に立つ AI アシスタントです。組織の名前と、DuckDuckGoSearch で検索した記事の抜粋を入力します。\n",
        "フィードバックを生成します。あなた自身の答えを書いてください。\n",
        "これはエンティティの名前です: {output_2}\n",
        "{output_2} の詳細な定義\n",
        "注記：\n",
        "1. 日本語で答えてください。\n",
        "2. 質問を繰り返したり、要求以上の情報を求めたりしないでください。\n",
        "3. 質問に回答する記事がない場合、または回答がない場合は結果が表示されません\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "4G6F4N4juLGa"
      },
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.chains import SequentialChain\n",
        "# from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "# # Define the first chain\n",
        "# first_chain_prompt = PromptTemplate(\n",
        "#     input_variables=[\"question\", \"context\"],\n",
        "#     template=template_japan\n",
        "# )\n",
        "# first_chain = LLMChain(llm=model, prompt=first_chain_prompt, output_key=\"output_1\")\n",
        "\n",
        "# # Define the second chain\n",
        "# second_chain_prompt = PromptTemplate(\n",
        "#     input_variables=[\"output_1\"],\n",
        "#     template=template2_japan\n",
        "# )\n",
        "# second_chain = LLMChain(llm=model, prompt=second_chain_prompt, output_key=\"output_2\")\n",
        "\n",
        "# #\n",
        "# prompt_3 = PromptTemplate(\n",
        "#     input_variables=[\"output_2\"],\n",
        "#     template=template3_japan\n",
        "# )\n",
        "\n",
        "# answer = prompt_3 | model | StrOutputParser()\n",
        "\n",
        "# format_out_docs = itemgetter(\"docs\") | RunnableLambda(format_docs_to_document)\n",
        "# format_out = itemgetter(\"docs\") | RunnableLambda(format_docs_to_links)\n",
        "\n",
        "# chain_search = (\n",
        "#     RunnableParallel(question=RunnablePassthrough(), docs=search)\n",
        "#         .assign(context=format_out_docs)\n",
        "#         .assign(output_3=answer)\n",
        "#         .assign(context=format_out)\n",
        "#         #.pick([\"answer\", \"context\"])\n",
        "# )\n",
        "\n",
        "\n",
        "# # Create the sequential chain\n",
        "\n",
        "# sequential_chain = SequentialChain(\n",
        "#     chains=[first_chain, second_chain],\n",
        "#     input_variables=[\"question\", \"context\"],\n",
        "#     output_variables=[\"output_1\", \"output_2\"],\n",
        "#     verbose=True\n",
        "# )\n",
        "\n",
        "# # # Run the pipeline\n",
        "# question = quess\n",
        "# result = sequential_chain.invoke({\"question\": question, \"context\": retrieval.get_relevant_documents(question)})\n",
        "\n",
        "# # print(\"Analysis:\", result)\n",
        "# print(result['output_2'])\n",
        "# # print(result['output_1'])\n",
        "\n",
        "# # first_chain.invoke({\"question\": question, \"context\": retrieval.get_relevant_documents(question)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTGeCOh8dGN1",
        "outputId": "620c7639-1610-4ff0-f44b-9a54436cd32f"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "エンティティ名：\n",
            "\n",
            "* 日本\n",
            "\n",
            "タイトル：\n",
            "\n",
            "* 日本の金融包摂 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NXMLf71Mr_7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain\n",
        "# from langchain.chains.api.api_search import ApiSearch\n",
        "from langchain.chains.api.api_search import ApiSearch\n",
        "\n",
        "# Define the LLM\n",
        "llm = model\n",
        "\n",
        "# Define the DuckDuckGo search\n",
        "ddg_search = ApiSearch(\n",
        "    api_url=\"https://api.duckduckgo.com/\",\n",
        "    input_keys=[\"query\"],\n",
        "    output_keys=[\"result\"]\n",
        ")\n",
        "\n",
        "# Define the sequential chain\n",
        "chain = SequentialChain(\n",
        "    chains=[\n",
        "        {\n",
        "            \"name\": \"llm\",\n",
        "            \"chain\": llm,\n",
        "            \"inputs\": {\"text\": \"What is the capital of France?\"},\n",
        "            \"outputs\": {\"output\": \"result\"}\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"ddg_search\",\n",
        "            \"chain\": search,\n",
        "            \"inputs\": {\"query\": \"result\"},\n",
        "            \"outputs\": {\"result\": \"search_result\"}\n",
        "        }\n",
        "    ],\n",
        "    input_variables=[\"text\"],\n",
        "    output_variables=[\"search_result\"]\n",
        ")\n",
        "\n",
        "# Run the chain\n",
        "result = chain({\"text\": \"What is the capital of France?\"})\n",
        "print(result[\"search_result\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "iU_722_u92Ez",
        "outputId": "50131aef-c5cb-4bcd-fdec-1d5f1df92af3"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain.chains.api.api_search'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-295-4e52cc0e81fd>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequentialChain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# from langchain.chains.api.api_search import ApiSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_search\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mApiSearch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Define the LLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain.chains.api.api_search'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vwLFOW_o92G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEK_2GzZ92Ky",
        "outputId": "69f5db7e-3d7e-4889-a771-426e73898dd2"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.10 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.11)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.4.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.10->langchain) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.10->langchain) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tzXo7bl292Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SequentialChain, LLMChain\n",
        "from langchain.chains.sequential import SimpleSequentialChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "AuHVB5dOlJgs"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1 = SimpleInputChain(\n",
        "    input_key=\"input\",\n",
        "    output_keys=[\"output1\", \"output2\"],\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"input\"],\n",
        "        template=\"This is the first chain: {input}\"\n",
        "    ),\n",
        "    return_values=[\"output1\", \"output2\"]\n",
        ")\n",
        "\n",
        "chain2 = LLMChain(\n",
        "    llm=model,\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"output1\"],\n",
        "        template=\"This is the second chain: {output1}\"\n",
        "    )\n",
        ")\n",
        "sequential_chain = SequentialChain(\n",
        "    chains=[chain1, chain2],\n",
        "    input_variables=[\"input\"],\n",
        "    output_variables=[\"output2\"],\n",
        "    verbose=True\n",
        ")\n",
        "result = sequential_chain.run(\"Hello, world!\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "KJq8As00lJkC",
        "outputId": "17e331dc-fd13-484f-f1cd-166c129b8c73"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'SimpleInputChain' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-210-3622de798d8c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m chain1 = SimpleInputChain(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0minput_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     prompt=PromptTemplate(\n\u001b[1;32m      5\u001b[0m         \u001b[0minput_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'SimpleInputChain' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt_1 = PromptTemplate.from_template(template_japan)\n",
        "\n",
        "# def format_output_chain_1(result):\n",
        "#   #[{'id': '/content/file.pdf:None:39', 'source': '/content/file.pdf'}, {'id': '/content/file.pdf:None:0', 'source': '/content/file.pdf'}, {'id': '/content/file.pdf:None:8', 'source': '/content/file.pdf'}]\n",
        "#   answer = result['result']\n",
        "#   context = result['source_documents']\n",
        "#   context_str = \"\"\n",
        "#   for doc in context:\n",
        "#     metadata = doc.metadata  # {'id': '/content/file.pdf:None:39', 'source': '/content/file.pdf'}\n",
        "#     for key, value in metadata.items():\n",
        "#         context_str += f\"{key}: {value}, \"\n",
        "#     context_str += \",\\n \"\n",
        "#   return {'answer_1': answer, 'context_1': context_str}\n",
        "\n",
        "# chain_type_kwargs = {\"prompt\": prompt_1}\n",
        "# qa_chain = RetrievalQA.from_chain_type(llm=model,\n",
        "#                                   chain_type=\"stuff\",\n",
        "#                                   retriever=retrieval,\n",
        "#                                   return_source_documents=True,\n",
        "#                                   chain_type_kwargs=chain_type_kwargs)\n",
        "# chain = (\n",
        "#     qa_chain\n",
        "#     | format_output_chain_1\n",
        "# )\n",
        "\n",
        "\n",
        "# class Output(BaseModel):\n",
        "#     name: str = Field(description=\"エンティティの名前またはヘッダーはコンテキスト内で抽出されます\")\n",
        "# parser = JsonOutputParser(pydantic_object=Output)\n",
        "\n",
        "# prompt_2 = PromptTemplate(\n",
        "#     template=template2_japan,\n",
        "#     input_variables=[\"context\"],\n",
        "#     partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        "# )\n",
        "# chain2 = (\n",
        "#     RunnableLambda(itemgetter(\"answer_1\"))\n",
        "#     | prompt_2\n",
        "#     | model\n",
        "#     | StrOutputParser()\n",
        "#     | {\"answer_1\": \"answer_1\", 'context_1': 'context_1', \"answer_2\": format_output_name_entity}\n",
        "# )\n",
        "\n",
        "\n",
        "# final_chain = (\n",
        "#     chain\n",
        "#     | chain2\n",
        "# )\n",
        "\n",
        "# final_chain.invoke(\"ベトナムにおける金融包摂の決定要因は何ですか?\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "PGOJkAAGmRS1",
        "outputId": "46269c92-9e0c-48d0-9c48-92229b60afca"
      },
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-209-ce55533c906c>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m )\n\u001b[1;32m     36\u001b[0m chain2 = (\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mRunnableLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"answer_1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;34m|\u001b[0m \u001b[0mprompt_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m|\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m__or__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   2445\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2447\u001b[0;31m                 \u001b[0mcoerce_to_runnable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2448\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   5040\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mRunnableLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5041\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5042\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnableParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5043\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5044\u001b[0m         raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps__, **kwargs)\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m         super().__init__(  # type: ignore[call-arg]\n\u001b[0;32m-> 3015\u001b[0;31m             \u001b[0msteps__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcoerce_to_runnable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3016\u001b[0m         )\n\u001b[1;32m   3017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m         super().__init__(  # type: ignore[call-arg]\n\u001b[0;32m-> 3015\u001b[0;31m             \u001b[0msteps__\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcoerce_to_runnable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3016\u001b[0m         )\n\u001b[1;32m   3017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36mcoerce_to_runnable\u001b[0;34m(thing)\u001b[0m\n\u001b[1;32m   5042\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnableParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5043\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5044\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m   5045\u001b[0m             \u001b[0;34mf\"Expected a Runnable, callable or dict.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5046\u001b[0m             \u001b[0;34mf\"Instead got an unsupported type: {type(thing)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected a Runnable, callable or dict.Instead got an unsupported type: <class 'str'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ij_aKH7NmRVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TYP2XTHFmRXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yNMtRkTAmRZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1KZmJXNRmRbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = \"\"\"\n",
        "| 項目 | 2022年度 | 2023年度 | 2025年3月期予測 | 2026年3月期予測 | 2027年3月期予測 | 2028年3月期予測 | 2029年3月期予測 |\n",
        "|---|---|---|---|---|---|---|---|\n",
        "| **営業活動によるキャッシュフロー** | 101,610,807 | 127,081,966 | 177,914,752 | 237,219,165 | 316,292,219 | 421,722,959 | 562,297,279 |\n",
        "|   | 税引前当期純利益 | 36,464,000 | 52,091,000 | 72,927,400 | 97,236,715 | 129,648,953 | 172,865,271 | 230,486,628 |\n",
        "|   | 減価償却費 |  |  |  |  |  |  |  |\n",
        "|   | その他 | 65,146,807 | 74,990,966 | 104,987,352 | 139,982,450 | 186,643,266 | 248,857,688 | 331,810,651 |\n",
        "| **投資活動によるキャッシュフロー** | 118,024 | -5,478,410 | -7,669,774 | -10,226,366 | -13,635,154 | -18,180,206 | -24,240,274 |\n",
        "|   | 有形固定資産の取得による支出 |  |  |  |  |  |  |  |\n",
        "|   | 無形固定資産の取得による支出 |  |  |  |  |  |  |  |\n",
        "|   | 投資有価証券の取得による支出 |  |  |  |  |  |  |  |\n",
        "|   | その他 | 118,024 | -5,478,410 | -7,669,774 | -10,226,366 | -13,635,154 | -18,180,206 | -24,240,274 |\n",
        "| **財務活動によるキャッシュフロー** | 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
        "|   | 短期借入金の純増減額 |  |  |  |  |  |  |  |\n",
        "|   | 長期借入金の純増減額 |  |  |  |  |  |  |  |\n",
        "|   | その他 |  |  |  |  |  |  |  |\n",
        "| **現金及び現金同等物に係る換算差額** |  |  |  |  |  |  |  |\n",
        "| **現金及び現金同等物に係る増減額** | 67,641,866 | 121,603,556 | 170,244,978 | 226,992,799 | 302,657,065 | 403,542,753 | 538,057,005 |\n",
        "| **現金及び現金同等物の期首残高** | 104,491,954 | 172,133,820 | 342,378,798 | 569,371,597 | 872,028,662 | 1,275,571,415 | 1,679,114,168 |\n",
        "| **現金及び現金同等物の期末残高** | 172,133,820 | 293,737,376 | 512,623,776 | 796,364,396 | 1,174,685,727 | 1,679,114,168 | 2,217,171,173 |\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FgSNjLqwmRdP"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# template_ = \"\"\"\n",
        "# あなたは、CSV および Excel 財務ファイルの構造の分析と合成を専門とする AI アシスタントです。以下に提供される情報を使用して、特定の属性に共通する単語レベルで要約してください。親属性には子属性が含まれ、子属性にはより小さな子属性が含まれます...\n",
        "\n",
        "# 下記の内容をJSONフォーマットに変換してください。\n",
        "#   \"キャッシュ・フロー計算書\":\n",
        "#     \"?年度\":\n",
        "#       \"営業活動によるキャッシュフロー\":\n",
        "#         \"?\": ?,\n",
        "#         ...,\n",
        "#         \"合計\": ?\n",
        "#       ,\n",
        "#       \"財務活動によるキャッシュフロー\":\n",
        "#         \"?\": ?,\n",
        "#         ...,\n",
        "#         \"合計\": ?\n",
        "#       ,\n",
        "#       \"財務活動によるキャッシュフロー\":\n",
        "#         \"?\": ?,\n",
        "#         ...,\n",
        "#         \"合計\": ?\n",
        "#        ,\n",
        "#     \"現金及び現金同等物に係る換算差額\": ?,\n",
        "#     \"現金及び現金同等物に係る増減額\": ?,\n",
        "#     \"現金及び現金同等物の期首残高\": ?,\n",
        "#     \"現金及び現金同等物の期末残高\": ?\n",
        "\n",
        "# 1. まず、Excel または CSV の列名のリストをコンテキスト内で取得し、それを理解します。\n",
        "# 2. 次に、その階層を json として提供します。\n",
        "# 3. 最小のサブ属性を決定した後。関連する各サブ属性の代表的なプロパティおよび財務的価値となるすべてのフィールド名を確認して取得します。そのフィールドの各キーと値を追加します。最後にそれを json に追加します (フィールド名は、見つかったばかりの値のキー属性であり、既知の列名のリスト内の列名に対応します)。\n",
        "#   3.1.まず、これらのフィールドを JSON アーキテクチャに追加します。\n",
        "# テキスト情報は Excel ファイルから取得され、各行は '\\n' で分割され、各セルの値は ' | で分割されます。 '。\n",
        "# これは、関連する財務属性と値の内容を含むコンテキストです: {context}\n",
        "# 次の質問を使用して、質問に対する回答を合成します: {question}\n",
        "# \"\"\""
      ],
      "metadata": {
        "id": "8VUVmU0gmRfc"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_ = \"\"\"\n",
        "下記の内容をJSONフォーマットに変換してください。\n",
        "  \"キャッシュ・フロー計算書\":\n",
        "    \"?年度\":\n",
        "      \"営業活動によるキャッシュフロー\":\n",
        "        \"?\": ?,\n",
        "        ...,\n",
        "        \"合計\": ?\n",
        "      ,\n",
        "      \"財務活動によるキャッシュフロー\":\n",
        "        \"?\": ?,\n",
        "        ...,\n",
        "        \"合計\": ?\n",
        "      ,\n",
        "      \"財務活動によるキャッシュフロー\":\n",
        "        \"?\": ?,\n",
        "        ...,\n",
        "        \"合計\": ?\n",
        "       ,\n",
        "    \"現金及び現金同等物に係る換算差額\": ?,\n",
        "    \"現金及び現金同等物に係る増減額\": ?,\n",
        "    \"現金及び現金同等物の期首残高\": ?,\n",
        "    \"現金及び現金同等物の期末残高\": ?\n",
        "\n",
        "テキスト情報は Excel ファイルから取得され、各行は '\\n' で分割され、各セルの値は ' | で分割されます。 '。\n",
        "これは、関連する財務属性と値の内容を含むコンテキストです: {context}\n",
        "次の質問を使用して、質問に対する回答を合成します: {question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "b_xZfZ1BTvQO"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_test = PromptTemplate.from_template(template_)\n",
        "chain = (\n",
        "    prompt_test\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "question = \"Follow the prompt template to answer and question\"\n",
        "\n",
        "text = chain.invoke({\"context\": doc, \"question\": question})"
      ],
      "metadata": {
        "id": "L-9n8L0_mRhl"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "rq4Ex8B9Ndd-",
        "outputId": "145ec585-ff24-4d0f-8dea-c8eceeeb839a"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```json\\n{\\n  \"キャッシュ・フロー計算書\": {\\n    \"2022年度\": {\\n      \"営業活動によるキャッシュフロー\": {\\n        \"税引前当期純利益\": 36464000,\\n        \"減価償却費\": null,\\n        \"その他\": 65146807,\\n        \"合計\": 101610807\\n      },\\n      \"投資活動によるキャッシュフロー\": {\\n        \"有形固定資産の取得による支出\": null,\\n        \"無形固定資産の取得による支出\": null,\\n        \"投資有価証券の取得による支出\": null,\\n        \"その他\": 118024,\\n        \"合計\": 118024\\n      },\\n      \"財務活動によるキャッシュフロー\": {\\n        \"短期借入金の純増減額\": null,\\n        \"長期借入金の純増減額\": null,\\n        \"その他\": null,\\n        \"合計\": 0\\n      },\\n      \"現金及び現金同等物に係る換算差額\": null,\\n      \"現金及び現金同等物に係る増減額\": 67641866,\\n      \"現金及び現金同等物の期首残高\": 104491954,\\n      \"現金及び現金同等物の期末残高\": 172133820\\n    },\\n    \"2023年度\": {\\n      \"営業活動によるキャッシュフロー\": {\\n        \"税引前当期純利益\": 52091000,\\n        \"減価償却費\": null,\\n        \"その他\": 74990966,\\n        \"合計\": 127081966\\n      },\\n      \"投資活動によるキャッシュフロー\": {\\n        \"有形固定資産の取得による支出\": null,\\n        \"無形固定資産の取得による支出\": null,\\n        \"投資有価証券の取得による支出\": null,\\n        \"その他\": -5478410,\\n        \"合計\": -5478410\\n      },\\n      \"財務活動によるキャッシュフロー\": {\\n        \"短期借入金の純増減額\": null,\\n        \"長期借入金の純増減額\": null,\\n        \"その他\": null,\\n        \"合計\": 0\\n      },\\n      \"現金及び現金同等物に係る換算差額\": null,\\n      \"現金及び現金同等物に係る増減額\": 121603556,\\n      \"現金及び現金同等物の期首残高\": 172133820,\\n      \"現金及び現金同等物の期末残高\": 293737376\\n    },\\n    \"2025年3月期予測\": {\\n      \"営業活動によるキャッシュフロー\": {\\n        \"税引前当期純利益\": 72927400,\\n        \"減価償却費\": null,\\n        \"その他\": 104987352,\\n        \"合計\": 177914752\\n      },\\n      \"投資活動によるキャッシュフロー\": {\\n        \"有形固定資産の取得による支出\": null,\\n        \"無形固定資産の取得による支出\": null,\\n        \"投資有価証券の取得による支出\": null,\\n        \"その他\": -7669774,\\n        \"合計\": -7669774\\n      },\\n      \"財務活動によるキャッシュフロー\": {\\n        \"短期借入金の純増減額\": null,\\n        \"長期借入金の純増減額\": null,\\n        \"その他\": null,\\n        \"合計\": 0\\n      },\\n      \"現金及び現金同等物に係る換算差額\": null,\\n      \"現金及び現金同等物に係る増減額\": 170244978,\\n      \"現金及び現金同等物の期首残高\": 342378798,\\n      \"現金及び現金同等物の期末残高\": 512623776\\n    },\\n    \"2026年3月期予測\": {\\n      \"営業活動によるキャッシュフロー\": {\\n        \"税引前当期純利益\": 97236715,\\n        \"減価償却費\": null,\\n        \"その他\": 139982450,\\n        \"合計\": 237219165\\n      },\\n      \"投資活動によるキャッシュフロー\": {\\n        \"有形固定資産の取得による支出\": null,\\n        \"無形固定資産の取得による支出\": null,\\n        \"投資有価証券の取得による支出\": null,\\n        \"その他\": -10226366,\\n        \"合計\": -10226366\\n      },\\n      \"財務活動によるキャッシュフロー\": {\\n        \"短期借入金の純増減額\": null,\\n        \"長期借入金の純増減額\": null,\\n        \"その他\": null,\\n        \"合計\": 0\\n      },\\n      \"現金及び現金同等物に係る換算差額\": null,\\n      \"現金及び現金同等物に係る増減額\": 226992799,\\n      \"現金及び現金同等物の期首残高\": 569371597,\\n      \"現金及び現金同等物の期末残高\": 796364396\\n    },\\n    \"2027年3月期予測\": {\\n      \"営業活動によるキャッシュフロー\": {\\n        \"税引前当期純利益\": 129648953,\\n        \"減価償却費\": null,\\n        \"その他\": 186643266,\\n        \"合計\": 316292219\\n      },\\n      \"投資活動によるキャッシュフロー\": {\\n        \"有形固定資産の取得による支出\": null,\\n        \"無形固定資産の取得による支出\": null,\\n        \"投資有価証券の取得による支出\": null,\\n        \"その他\": -13635154,\\n        \"合計\": -13635154\\n      },\\n      \"財務活動によるキャッシュフロー\": {\\n        \"短期借入金の純増減額\": null,\\n        \"長期借入金の純増減額\": null,\\n        \"その他\": null,\\n        \"合計\": 0\\n      },\\n      \"現金及び現金同等物に係る換算差額\": null,\\n      \"現金及び現金同等物に係る増減額\": 302657065,\\n      \"現金及び現金同等物の期首残高\": 796364396,\\n      \"現金及び現金同等物の期末残高\": 1174685727\\n    },\\n    \"2028年3月期予測\": {\\n      \"営業活動によるキャッシュフロー\": {\\n        \"税引前当期純利益\": 172865271,\\n        \"減価償却費\": null,\\n        \"その他\": 248857688,\\n        \"合計\": 421722959\\n      },\\n      \"投資活動によるキャッシュフロー\": {\\n        \"有形固定資産の取得による支出\": null,\\n        \"無形固定資産の取得による支出\": null,\\n        \"投資有価証券の取得による支出\": null,\\n        \"その他\": -18180206,\\n        \"合計\": -18180206\\n      },\\n      \"財務活動によるキャッシュフロー\": {\\n        \"短期借入金の純増減額\": null,\\n        \"長期借入金の純増減額\": null,\\n        \"その他\": null,\\n        \"合計\": 0\\n      },\\n      \"現金及び現金同等物に係る換算差額\": null,\\n      \"現金及び現金同等物に係る増減額\": 403542753,\\n      \"現金及び現金同等物の期首残高\": 1174685727,\\n      \"現金及び現金同等物の期末残高\": 1679114168\\n    },\\n    \"2029年3月期予測\": {\\n      \"営業活動によるキャッシュフロー\": {\\n        \"税引前当期純利益\": 230486628,\\n        \"減価償却費\": null,\\n        \"その他\": 331810651,\\n        \"合計\": 562297279\\n      },\\n      \"投資活動によるキャッシュフロー\": {\\n        \"有形固定資産の取得による支出\": null,\\n        \"無形固定資産の取得による支出\": null,\\n        \"投資有価証券の取得による支出\": null,\\n        \"その他\": -24240274,\\n        \"合計\": -24240274\\n      },\\n      \"財務活動によるキャッシュフロー\": {\\n        \"短期借入金の純増減額\": null,\\n        \"長期借入金の純増減額\": null,\\n        \"その他\": null,\\n        \"合計\": 0\\n      },\\n      \"現金及び現金同等物に係る換算差額\": null,\\n      \"現金及び現金同等物に係る増減額\": 538057005,\\n      \"現金及び現金同等物の期首残高\": 1679114168,\\n      \"現金及び現金同等物の期末残高\": 2217171173\\n    }\\n  }\\n}\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 315
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r'/content/document2.txt', 'w', encoding=\"utf-8\") as file:\n",
        "  file.write(text)"
      ],
      "metadata": {
        "id": "5UQFkLOpNdf-"
      },
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kerYYst0Ndh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HwEOtOWpmRjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MPyiI99xmRl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "filename = Path('file2.pdf')\n",
        "url = 'https://www.dir.co.jp/report/research/capital-mkt/esg/20230508_023782.pdf'\n",
        "response = requests.get(url)\n",
        "filename.write_bytes(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vKBC5XBlJpk",
        "outputId": "70161fa1-c2a5-42a5-fdb2-67402299393c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "988432"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}